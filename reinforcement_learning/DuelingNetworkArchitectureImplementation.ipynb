{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "TDL4T4160P-8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21905,
     "status": "ok",
     "timestamp": 1665042566743,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "TDL4T4160P-8",
    "outputId": "f5f0c89a-3413-4a14-b0ac-91798038dadf"
   },
   "outputs": [],
   "source": [
    " #!pip install gym[atari,accept-rom-license]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Lab36Cm53hT3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1666077971727,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "Lab36Cm53hT3",
    "outputId": "685e3000-67fa-4bb3-e1ec-7a50773a17f0"
   },
   "outputs": [],
   "source": [
    "# !apt install xvfb\n",
    "# !pip install gym-notebook-wrapper\n",
    "# !pip show tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84dfbf-263e-4d9a-ad88-2eaf271e4421",
   "metadata": {
    "id": "ae84dfbf-263e-4d9a-ad88-2eaf271e4421"
   },
   "source": [
    "# Dueling Network Architecture Implementation\n",
    "The Duelling network is an artificial neural network architecture that has improved the state of the art in the DQN area used in combination with Dual DQN and Prioritized Experience Replay. This approach splits the action value calculation using a combination of state value function and advantage function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc578666-0c50-4681-8b90-bc48ece391d6",
   "metadata": {
    "id": "fc578666-0c50-4681-8b90-bc48ece391d6"
   },
   "source": [
    "# Searching for available environments\n",
    "We want to test the performance of our architecture with the Atari game 'Phoenix'.\n",
    "Here we check which kind of versions of this game are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d78d38-4889-44d7-a8cd-49d3c9059bad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1539,
     "status": "ok",
     "timestamp": 1665042568266,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "82d78d38-4889-44d7-a8cd-49d3c9059bad",
    "outputId": "9d44fd58-f58f-4b95-cfa9-f00f7d2a04e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALE/Phoenix-ram-v5\n",
      "ALE/Phoenix-v5\n",
      "Phoenix-ram-v0\n",
      "Phoenix-ram-v4\n",
      "Phoenix-ramDeterministic-v0\n",
      "Phoenix-ramDeterministic-v4\n",
      "Phoenix-ramNoFrameskip-v0\n",
      "Phoenix-ramNoFrameskip-v4\n",
      "Phoenix-v0\n",
      "Phoenix-v4\n",
      "PhoenixDeterministic-v0\n",
      "PhoenixDeterministic-v4\n",
      "PhoenixNoFrameskip-v0\n",
      "PhoenixNoFrameskip-v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ste/anaconda3/lib/python3.9/site-packages/requests/packages/urllib3/_collections.py:2: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import Mapping, MutableMapping\n"
     ]
    }
   ],
   "source": [
    "from gym import envs\n",
    "\n",
    "# Searching for available environments\n",
    "game_name = \"Phoenix\"\n",
    "all_envs = envs.registry.values()\n",
    "env_ids = [env_spec.id for env_spec in all_envs]\n",
    "\n",
    "for id in sorted(env_ids):\n",
    "    if game_name in id:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5b1aa-6e92-4ac3-9079-c49121fafaef",
   "metadata": {
    "id": "12c5b1aa-6e92-4ac3-9079-c49121fafaef"
   },
   "source": [
    "# Environment Configuration\n",
    "We select the version 4 of the environment with no frame skipping and select as render mode human. The no frame skipping is used to make this environment compatible with the optimization made by *AtariPreprocessing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cecf335-3193-4ce8-90f5-dfe1c3a82e5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1665042568266,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "3cecf335-3193-4ce8-90f5-dfe1c3a82e5f",
    "outputId": "28ea8b12-3721-41e2-a222-156e9e23bd33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.wrappers import AtariPreprocessing\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# Make Parameters:\n",
    "game_name = \"Phoenix\"\n",
    "game_mode = \"NoFrameskip\"  # [Deterministic | NoFrameskip | ram | ramDeterministic | ramNoFrameskip ]\n",
    "game_version = \"v4\"  # [v0 | v4 | v5]\n",
    "env_name = '{}{}-{}'.format(game_name, game_mode, game_version)\n",
    "env_render_mode = 'human'  # [human | rgb_array]\n",
    "env_frame_skip = 4\n",
    "\n",
    "env = gym.make(env_name, render_mode=env_render_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b68bf0-d09a-432b-9fe9-9991f0d8a84a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1665042568267,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "23b68bf0-d09a-432b-9fe9-9991f0d8a84a",
    "outputId": "1921b05a-a9fa-47f2-9246-26adafe63578"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ste/anaconda3/lib/python3.9/site-packages/gym/core.py:51: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:297: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1d99d69af0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env.reset() \n",
    "state = env.render(mode=\"rgb_array\")\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04326819-e929-40fe-9a26-ecfc317f7882",
   "metadata": {
    "id": "04326819-e929-40fe-9a26-ecfc317f7882"
   },
   "source": [
    "## Enviornment Observations\n",
    "Below we have a first look at the environment characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143cf671-a4e9-46a5-b06c-5f66f83fdc22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1665042568267,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "143cf671-a4e9-46a5-b06c-5f66f83fdc22",
    "outputId": "ffd6528b-5a7d-4fbf-d9e5-c4aad9150b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401a5ee2-bf0f-4721-be41-32c498caf4f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1665042568268,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "401a5ee2-bf0f-4721-be41-32c498caf4f3",
    "outputId": "ef5b5156-1509-47c2-98e8-2ffa96ea7495"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c5513e8-9f39-47bd-b667-a7436383795e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1665042568268,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "2c5513e8-9f39-47bd-b667-a7436383795e",
    "outputId": "f6792f4c-9ef4-485e-ef92-4875a0e28914"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'DOWN', 'RIGHTFIRE', 'LEFTFIRE', 'DOWNFIRE']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad4449-5a13-4032-9645-53f78265617b",
   "metadata": {
    "id": "39ad4449-5a13-4032-9645-53f78265617b"
   },
   "source": [
    "## Environment Optimization\n",
    "We optimize the environment by adding the frame skipping, changing its observation in greyscale and following the experiment done in the paper we set to at most 30 the no-op actions; to get this we use the AtariPreprocessing wrapper.\n",
    "We use Framestack to create observations of 4 frames to give the idea of movement to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a89f89-355e-407a-a036-d1d14bfe3fba",
   "metadata": {
    "id": "63a89f89-355e-407a-a036-d1d14bfe3fba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ste/anaconda3/lib/python3.9/site-packages/gym/core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = AtariPreprocessing(env, frame_skip=env_frame_skip, grayscale_obs=True, terminal_on_life_loss=False, noop_max=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43876bf8-8f34-4118-990a-dba1bbbc67fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1665042569152,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "43876bf8-8f34-4118-990a-dba1bbbc67fd",
    "outputId": "bead8004-41c7-4082-d536-f1d6bce913c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ste/anaconda3/lib/python3.9/site-packages/gym/utils/passive_env_checker.py:227: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1d997cd7f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = FrameStack(env, 4)\n",
    "state = env.reset()\n",
    "plt.imshow(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c6620c-52ee-48de-bc6b-4caba64b8f1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1665042569153,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "51c6620c-52ee-48de-bc6b-4caba64b8f1f",
    "outputId": "4c23526d-3fe5-4795-bba8-e84ad50f9222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0735fbbc-11c3-418f-8026-f3eba9dc5cb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1665042569153,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "0735fbbc-11c3-418f-8026-f3eba9dc5cb9",
    "outputId": "ce6cfa59-1f25-4917-d5c2-b5aa4a49c4c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dccc025-b2ae-48c8-a70d-0e146d5c9d7c",
   "metadata": {
    "id": "9dccc025-b2ae-48c8-a70d-0e146d5c9d7c"
   },
   "source": [
    "# Network configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579e3d9-51f6-4612-bf77-25db75a98d4a",
   "metadata": {
    "id": "e579e3d9-51f6-4612-bf77-25db75a98d4a"
   },
   "source": [
    "## Policy\n",
    "The policy is the component that chooses the action to perform; using an $\\epsilon$-gready policy the action chosen can be a random with probability $\\epsilon$ or an action suggested by the ANN with probability $1 - \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c3213c2-3be1-4337-bf89-5a32f9dbf2c8",
   "metadata": {
    "id": "7c3213c2-3be1-4337-bf89-5a32f9dbf2c8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class EpsilonGreedyPolicy:\n",
    "\n",
    "    def __init__(self, model, action_space_size, episodes=1, min_epsilon=0):\n",
    "        self.model = model\n",
    "        self.action_space_size = action_space_size\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.episode = 1\n",
    "        self.episodes = episodes\n",
    "\n",
    "    def get_action(self, state):\n",
    "        epsilon = max(1 - self.episode / self.episodes, self.min_epsilon)\n",
    "        random = np.random.random()\n",
    "        # print(random, epsilon)\n",
    "        if random < epsilon:\n",
    "            action = np.random.randint(self.action_space_size)\n",
    "            return action\n",
    "        else:\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = self.model(state_tensor, training=False)\n",
    "            \n",
    "            action = tf.argmax(action_probs[0]).numpy()\n",
    "            return action\n",
    "\n",
    "    def next_episode(self):\n",
    "        self.episode += 1\n",
    "\n",
    "    def reset_episodes(self):\n",
    "        self.episode = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c4fef-7fd8-4e38-9eac-b7623174d588",
   "metadata": {
    "id": "255c4fef-7fd8-4e38-9eac-b7623174d588"
   },
   "source": [
    "## Replication Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f6dd9-3076-4c01-bf7f-01b9400c6fc2",
   "metadata": {
    "id": "6d9f6dd9-3076-4c01-bf7f-01b9400c6fc2"
   },
   "source": [
    "### Prioritized experience replay\n",
    "The Prioritized experience replay was introduced in the paper \"Prioritized experience replay\" (https://arxiv.org/abs/1511.05952), it consists in an evolution of the replay buffer ordering the experiences to replay by priority. In this experiment we adopt the **rank-based** variant where the experience sampling from the buffer it's done with probability $ P(i) = \\frac{p_{i}^{\\alpha}}{\\sum_k{p_{k}^{\\alpha}}} $ and $p(i)=\\frac{1}{rank(i)}$ where $rank(i)$ is the rank of the transition *i*, $\\alpha$ is called **priority exponent**. It is necessary to compute the importance sampling weights as $w_j = \\frac{(N * P(j))^{-\\beta}}{max_i{w_i}} $ and $w_i = (\\frac{1}{N} . \\frac{1}{P(i)})^\\beta$ to avoid overfitting for the experiences with more priority.\n",
    "\n",
    "In both the paper the parameters are setted as follow: **priority exponent** $\\alpha= 0.7$,  the **importance sampling exponent** $\\beta = [0.5, 1]$.\n",
    "In the paper a heap array structure is proposed to implement the buffer. Due to the particular structure and the amount of property of the replay buffer in the Prioritized Experience Replay we choose to describe it as a class. The heap array structure is implemented as a list sorted every *T* step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e8897eb-7fea-48e8-93d4-cfd169a6278a",
   "metadata": {
    "id": "9e8897eb-7fea-48e8-93d4-cfd169a6278a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# We set a time to haepify to sort the buffer every K time step.\n",
    "class PrioritizedExperienceReplayRankBased:\n",
    "    \"\"\"\n",
    "    contains the tuples (TD_error, experience)\n",
    "    replay_buffer --- it's the max size of the buffer, over which before add an experience one is remove\n",
    "    max_buffer_size --- time step before sort the structure\n",
    "    time_to_haepify --- the last time step\n",
    "    mod_curr_step = 0  --- the alpha parameter used to calculate the probability of the i-th element P(i) to be sampled\n",
    "    alpha -- alpha parameter\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_buffer_size, step_to_heapify, alpha):\n",
    "        self.max_buffer_size = max_buffer_size\n",
    "        # (TD, experience)\n",
    "        # Probably list is not the most efficient structure to use np array ?\n",
    "        self.replay_buffer = []\n",
    "        self.alpha = alpha\n",
    "        self.heapify_threshold = step_to_heapify  # here we stock the threshold to sort the buffer\n",
    "        self.step_to_heapify = step_to_heapify  # number of next steps before heapify\n",
    "        self.max_td_error = 0\n",
    "\n",
    "    def set_alpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    # Add experience in the buffer mapping it with its last TD_error\n",
    "    def add_experience(self, experience):\n",
    "        if len(self.replay_buffer) == self.max_buffer_size:\n",
    "            self.remove_experience()\n",
    "\n",
    "        # New experience where td_error is unknown are set with the max td error\n",
    "        # NB we are considering the max td error as the error of the experience in first position, but the buffer may\n",
    "        # not have been sorted yet\n",
    "        if len(self.replay_buffer) > 0:\n",
    "            self.max_td_error = self.replay_buffer[0][0]\n",
    "\n",
    "        self.replay_buffer.append((self.max_td_error, experience))\n",
    "        self.step_to_heapify -= 1\n",
    "        if self.step_to_heapify == 0:\n",
    "            self.replay_buffer.sort(key=lambda el: el[0], reverse=True)\n",
    "            self.step_to_heapify = self.heapify_threshold\n",
    "\n",
    "    # Remove experience from the buffer\n",
    "    def remove_experience(self):\n",
    "        self.replay_buffer.pop(-1)\n",
    "\n",
    "    @staticmethod\n",
    "    def zip_f_sampling(alpha, n):\n",
    "        x = np.arange(1, n + 1)\n",
    "        weights = x ** (-alpha)\n",
    "        weights /= weights.sum()\n",
    "        zipf = stats.rv_discrete(values=(x, weights))\n",
    "        return zipf.rvs() - 1\n",
    "\n",
    "    # Get batch_size samples from the buffer; using the beta parameter to compute the importance sampling weight\n",
    "    # Beta value can change while training we can delegate its control outside\n",
    "    def sample_experience(self, batch_size, beta):\n",
    "        experiences = []\n",
    "        importance_sampling_weights = []\n",
    "        n = len(self.replay_buffer) - 1\n",
    "        indexes = []\n",
    "\n",
    "        for i in range(0, batch_size):\n",
    "            # Sample index and check the experience is not already present in the batch\n",
    "            index = self.zip_f_sampling(self.alpha, n)\n",
    "            while index in indexes:\n",
    "                index = self.zip_f_sampling(self.alpha, n)\n",
    "            indexes.append(index)\n",
    "            # importance sampling weights computation\n",
    "            rank = index + 1\n",
    "            pj = 1 / rank\n",
    "            importance_sampling_weights.append(((n * pj) ** (-beta)))\n",
    "            experiences.append(self.replay_buffer[index][1])\n",
    "\n",
    "        # Normalization step\n",
    "        max_weight = max(importance_sampling_weights)\n",
    "        importance_sampling_weights_normalized = np.divide(importance_sampling_weights, max_weight)\n",
    "        return indexes, experiences, importance_sampling_weights_normalized\n",
    "\n",
    "    def update_td_error(self, index, td_error):\n",
    "        self.replay_buffer[index] = [td_error, self.replay_buffer[index][1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb99df-922b-4ef1-9865-8d653c135eb8",
   "metadata": {
    "id": "5ddb99df-922b-4ef1-9865-8d653c135eb8"
   },
   "source": [
    "## Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e58cc1cd-e7dc-4f40-ba18-b5127abc5fff",
   "metadata": {
    "id": "e58cc1cd-e7dc-4f40-ba18-b5127abc5fff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 14:49:17.882736: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:513: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:521: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py:108: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object:\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py:110: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool:\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:22: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/tensorflow/python/ops/numpy_ops/np_random.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/h5py/__init__.py:46: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras as krs\n",
    "\n",
    "input_shape = env.observation_space.shape\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d096c-c9d8-4012-9400-25075d3779cc",
   "metadata": {
    "id": "257d096c-c9d8-4012-9400-25075d3779cc"
   },
   "source": [
    "## Neural Network Creation\n",
    "The network architecture proposed follows the structure used in *\"Dueling Network Architectures for Deep Reinforcement Learning\"* https://arxiv.org/abs/1511.06581 composed of 3 convolutional layers and 2 fully connected layers for each stream (advantage, value).\n",
    "It's possible to create a dueling network using the `DQNAgent` of `rl.agents.dqn` setting `enable_dueling_network=True` in the constructor, but the purpose of this experiment is to show how to develop it manually so it is not used.\n",
    "\n",
    "The output of the value stream and the output of the advantage stream are merged to obtain the action-value function in the last module of the network using the following formula:\n",
    "$$ Q(s, a; \\theta, \\alpha, \\beta) = V (s;\\theta, \\beta) + ( A(s, a; \\theta, \\alpha) − max_{a' ∈|A|} A(s, a'; \\theta, \\alpha)) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a878b21-2040-4ca8-aeff-3563499bf9f9",
   "metadata": {
    "id": "0a878b21-2040-4ca8-aeff-3563499bf9f9"
   },
   "outputs": [],
   "source": [
    "from tensorflow import math\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "\n",
    "\n",
    "def create_dueling_model(input_shape, number_actions):\n",
    "    backend.set_image_data_format('channels_first')\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutions on the frames on the screen\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "    value_stream_1 = layers.Dense(512)(layer4)\n",
    "    value_stream_2 = layers.Dense(1)(value_stream_1)  # scalar output size\n",
    "\n",
    "    advantage_stream_1 = layers.Dense(512)(layer4)\n",
    "    advantage_stream_2 = layers.Dense(number_actions)(advantage_stream_1)  # output size equal to the actions available\n",
    "\n",
    "    # Combination of the streams: a Q value for each state\n",
    "    q_values = value_stream_2 + math.subtract(advantage_stream_2, math.reduce_mean(advantage_stream_2, axis=1,\n",
    "                                                                                   keepdims=True))\n",
    "    # Alternative q_value\n",
    "    # q_value = value_stream_2 + (advantage_stream_2 - backend.max(advantage_stream_2, axis=1, keepdims=True))\n",
    "    return Model(inputs=[inputs], outputs=[q_values])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b2cfe-111c-4afe-a3c5-391066124fe3",
   "metadata": {
    "id": "ff1b2cfe-111c-4afe-a3c5-391066124fe3"
   },
   "source": [
    "# Agent \n",
    "Here we define a custom agent to perfom action in the environment using a DoubleDQN training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391a27a-28ac-4d3d-9c8f-b42bb303bd76",
   "metadata": {
    "id": "e391a27a-28ac-4d3d-9c8f-b42bb303bd76"
   },
   "source": [
    "## Play one step\n",
    "With this function we want to ask the policy what action must be chosen and perform it on the enironment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec3a88-954a-49f5-96b9-a6d34c29a16d",
   "metadata": {
    "id": "bdec3a88-954a-49f5-96b9-a6d34c29a16d"
   },
   "source": [
    "## Gradient \n",
    "In our scenario the gradient that is backpropageted to the last convolutional layer must be rescaled by $\\frac{1}{\\sqrt{2}}$. Furthermore we have to realize by hand the gradient clipping that is not realized by the optimizer since we are using a custom loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45bd489-2d61-4334-b692-51a88f5ecb29",
   "metadata": {
    "id": "c45bd489-2d61-4334-b692-51a88f5ecb29"
   },
   "source": [
    "## Double DQN Training\n",
    "Double DQN algorithm uses a second network, beyond the network used for the prediction. So in the training process the main network is used to choose an action and another to evaluate it, this permits to mitigate the overfitting present in the classic DQN. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gg9foUcDcp1r",
   "metadata": {
    "id": "gg9foUcDcp1r"
   },
   "source": [
    "## DQN Agent code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bad3e87-4bed-4e08-a34e-8a2e2fc06a83",
   "metadata": {
    "id": "6bad3e87-4bed-4e08-a34e-8a2e2fc06a83"
   },
   "outputs": [],
   "source": [
    "import math as mt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DuelDQNAgent:\n",
    "\n",
    "    ## We keep the creation model outside the agent to ensure a fine-grained control on it\n",
    "    def __init__(self, env, model, policy, model_target=None, optimizer=None, replay_buffer=None):\n",
    "        self.env = env\n",
    "        self.model_primary = model\n",
    "        self.model_target = model_target\n",
    "        self.policy = policy\n",
    "        self.optimizer = optimizer\n",
    "        self.replay_buffer = replay_buffer\n",
    "\n",
    "    def set_policy(self, policy):\n",
    "        self.policy = policy\n",
    "\n",
    "    # Execs one action receiving in input the environment, its state, the current episode.\n",
    "    # If training its true add the experience in the replay buffer\n",
    "    def play_one_step(self, state):\n",
    "        action = self.policy.get_action(state)\n",
    "        # print(\"action {}\".format(action))\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        return action, reward, next_state, done, info\n",
    "\n",
    "    # Play\n",
    "    def play(self):\n",
    "        state = self.env.reset()\n",
    "        steps = 0\n",
    "        cumulative_reward = 0\n",
    "        while True:\n",
    "            action, reward, next_state, done, info = self.play_one_step(state)\n",
    "            cumulative_reward += reward\n",
    "            if done:\n",
    "                print(\"DONE number of steps: {} reward:  {}\".format(steps, cumulative_reward))\n",
    "                break\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "        return steps, cumulative_reward\n",
    "\n",
    "    ## Double DQN Training\n",
    "    @staticmethod\n",
    "    def gradient_clipping(gradients, clipping_value):\n",
    "        clipped_gradients = [(tf.clip_by_norm(grad, clipping_value)) for grad in gradients]\n",
    "        return clipped_gradients\n",
    "\n",
    "    def weighted_gradient(self, best_on_target_q_values, importance_sampling_weights, states, loss_function, mask,\n",
    "                          step_size=1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(importance_sampling_weights)\n",
    "            all_q_values = self.model_primary(states)\n",
    "            q_values = tf.reduce_sum(all_q_values * mask, axis=1, keepdims=True)\n",
    "            loss_value = loss_function(best_on_target_q_values, q_values)\n",
    "            loss_corrected = tf.multiply(loss_value, importance_sampling_weights, step_size)\n",
    "        grads = tape.gradient(loss_corrected, self.model_primary.trainable_variables)\n",
    "        return grads, loss_value\n",
    "\n",
    "    @staticmethod\n",
    "    def rescale_grad(gradients, rescale_value, index):\n",
    "        tensor_to_scale = gradients[index]\n",
    "        rescaled_tensor = tf.multiply(tensor_to_scale, rescale_value)\n",
    "        gradients[index] = rescaled_tensor\n",
    "        return gradients\n",
    "\n",
    "    # Collects samples of the previous experiences from the replay buffer\n",
    "    # and use them to improve the weights update of the Neural Network.\n",
    "    def double_dqn_training_step(self, batch_size, loss_function, discount_factor, clipping_value, beta, step_size=1):\n",
    "        indexes, experiences, importance_sampling_weights = self.replay_buffer.sample_experience(batch_size, beta)\n",
    "        states, actions, rewards, next_states, dones = [np.array([experience[field_index] for experience in experiences]\n",
    "                                                                 ) for field_index in range(5)]\n",
    "\n",
    "        action_space = self.env.action_space.n\n",
    "        # Predict using the primary network\n",
    "        next_q_values = self.model_primary.predict(next_states)\n",
    "        next_q_values_target = self.model_target.predict(next_states)\n",
    "        \n",
    "        # Select the action that lead us to the higher next Q value\n",
    "        best_actions = np.argmax(next_q_values, axis=1)\n",
    "        best_action_mask = tf.one_hot(best_actions, action_space)\n",
    "\n",
    "        next_q_value_target = tf.reduce_sum(next_q_values_target * best_action_mask, axis=1)\n",
    "        best_on_target_q_values = (rewards + (1-dones)*discount_factor*next_q_value_target)\n",
    "        # Add a negative reward when the agent die\n",
    "        best_on_target_q_values = best_on_target_q_values * (1-dones) - dones\n",
    "\n",
    "        mask = tf.one_hot(actions, action_space)\n",
    "        importance_sampling_weights = tf.convert_to_tensor(importance_sampling_weights, tf.float32)\n",
    "        weighted_gradient, loss_value = self.weighted_gradient(best_on_target_q_values, importance_sampling_weights,\n",
    "                                                               states, loss_function, mask, step_size)\n",
    "\n",
    "        for index, td_error in zip(indexes, loss_value):\n",
    "            self.replay_buffer.update_td_error(index, abs(td_error))\n",
    "\n",
    "        # We rescale the last convolutional layer to 1/sqrt(2) to balance the double backpropagation\n",
    "        rescale_value = (1 / mt.sqrt(2))\n",
    "        # The index of the last sequential layer\n",
    "        index_gradient_to_rescale = 4\n",
    "        rescaled_grads = self.rescale_grad(weighted_gradient, rescale_value, index_gradient_to_rescale)\n",
    "\n",
    "        # Since we are in a custom loop we have to clip the gradient by hand, we can't delegate it to the optimizer\n",
    "        clipped_gradients = self.gradient_clipping(rescaled_grads, clipping_value)\n",
    "        # Application gradient descent trough optimizer\n",
    "        self.optimizer.apply_gradients(zip(clipped_gradients, self.model_primary.trainable_variables))\n",
    "\n",
    "    # We use the training step just when there is enough samples on the replay buffer\n",
    "    def double_dqn_training(self, batch_size, loss_function, discount_factor, freq_replacement, training_freq,\n",
    "                            clipping_value, beta_min, beta_max, max_episodes=600):\n",
    "        rewards = []\n",
    "        steps = []\n",
    "        \n",
    "\n",
    "        for episode in range(1, max_episodes+1):\n",
    "            state = self.env.reset()\n",
    "            cumulative_reward = 0\n",
    "            step = 0\n",
    "            beta = max(beta_min, (beta_max * episode / max_episodes))\n",
    "\n",
    "            while True:\n",
    "                action, reward, next_state, done, info = self.play_one_step(state)\n",
    "                experience = [state, action, reward, next_state, done]\n",
    "                cumulative_reward += reward\n",
    "                self.replay_buffer.add_experience(experience)\n",
    "                if done:\n",
    "                    print(\n",
    "                        \"DONE episode = {} number of steps = {} reward = {}\".format(episode, step, cumulative_reward))\n",
    "                    rewards.append(cumulative_reward)\n",
    "                    steps.append(step)\n",
    "                    break\n",
    "                if len(self.replay_buffer.replay_buffer) > batch_size and (step % training_freq) == 0:\n",
    "                    self.double_dqn_training_step(batch_size, loss_function, discount_factor, clipping_value, beta)\n",
    "                if (step % freq_replacement) == 0:\n",
    "                    self.model_target.set_weights(self.model_primary.get_weights())\n",
    "                state = next_state\n",
    "                step = step + 1\n",
    "\n",
    "            self.policy.next_episode()\n",
    "        return steps, rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538fe86-67f4-4292-b80c-0225a088b271",
   "metadata": {
    "id": "9538fe86-67f4-4292-b80c-0225a088b271"
   },
   "source": [
    "## Result plots\n",
    "We use this function to generate the plot representing the rewards or the steps for each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ef6ec3d-002c-4d30-9052-4e05db6839a0",
   "metadata": {
    "id": "6ef6ec3d-002c-4d30-9052-4e05db6839a0"
   },
   "outputs": [],
   "source": [
    "def plot_result(x_label, y_label, x, y, name):\n",
    "    plt.ylabel(x_label)\n",
    "    plt.xlabel(y_label)\n",
    "    plt.plot(x, y)\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364dba26-35cc-4d53-878a-6bf0496b5a24",
   "metadata": {
    "id": "364dba26-35cc-4d53-878a-6bf0496b5a24"
   },
   "source": [
    "# Training\n",
    "The learning step is executed with the **Double Deep Q-networks** algorithm presented in the paper *\"Deep reinforcement learning with double Q-learning\"*.https://arxiv.org/pdf/1509.06461.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e16f49-345d-460c-922d-f529d9291a07",
   "metadata": {
    "id": "23e16f49-345d-460c-922d-f529d9291a07"
   },
   "source": [
    "## Training parameters\n",
    "We adopt as optimizer the **Adam** implementation setting the learning rate equal to $6.25x10^{-5}$ and **clipping the gradient** norm at most to 10; the parameters are specified in the paper \"*Deep reinforcement learning with double Q-learning*\" (https://arxiv.org/pdf/1509.06461.pdf)\n",
    "To evaluate the loss score we use the `mean_squared_error`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4742cf2f-c7c6-403e-9da9-32d47e7717da",
   "metadata": {
    "id": "4742cf2f-c7c6-403e-9da9-32d47e7717da"
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Environment info\n",
    "input_shape = env.observation_space.shape\n",
    "actions_number = env.action_space.n\n",
    "\n",
    "# Model persistent file\n",
    "primary_model_file_name = \"{}_dueling_model\".format(game_name)\n",
    "\n",
    "# Training Parameters\n",
    "loss_function = losses.mean_squared_error\n",
    "batch_size = 32 # @param {type:\"integer\"}\n",
    "discount_factor = 0.95 # @param {type:\"number\"}\n",
    "learning_rate = 6.25e-5 # @param {type:\"number\"}\n",
    "episodes = 1000 # @param {type:\"integer\"}\n",
    "clipping_value = 10 # @param {type:\"number\"}\n",
    "training_freq = 4 # @param {type:\"integer\"}\n",
    "\n",
    "# Dual DQN Training\n",
    "freq_replacement = 1000 # @param {type:\"integer\"}\n",
    "\n",
    "# Replay buffer parameters\n",
    "buffer_size = 10000 # @param {type:\"integer\"}\n",
    "step_to_heapify = 200 # @param {type:\"integer\"}\n",
    "alpha = 0.7 # @param {type:\"number\"}\n",
    "beta_max = 1 # @param {type:\"number\"}\n",
    "beta_min = 0.5 # @param {type:\"number\"}\n",
    "\n",
    "# Policy parameters\n",
    "min_epsilon = 0.01 # @param {type:\"number\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf7e90-0940-497c-8dc3-cafa5366bc3f",
   "metadata": {
    "id": "5fbf7e90-0940-497c-8dc3-cafa5366bc3f"
   },
   "source": [
    "## Model creation / loading \n",
    "In this step we check whether there is an already saved model and load it in that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e76e0d-1130-47d8-b055-dbaa73907926",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3653,
     "status": "ok",
     "timestamp": 1665042575453,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "44e76e0d-1130-47d8-b055-dbaa73907926",
    "outputId": "49ca5eb3-67e4-44d7-a61a-02e830afe86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an existing model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 14:49:18.883443: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-20 14:49:18.884279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-10-20 14:49:18.911616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:18.911739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-10-20 14:49:18.911763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-20 14:49:18.913106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-20 14:49:18.913142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-10-20 14:49:18.914320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-20 14:49:18.914530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-20 14:49:18.915925: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-20 14:49:18.916662: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-20 14:49:18.919939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-20 14:49:18.920066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:18.920245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:18.920330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-20 14:49:18.920785: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-20 14:49:18.921228: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-20 14:49:18.921322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:18.921427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-10-20 14:49:18.921463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-20 14:49:18.921496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-10-20 14:49:18.921515: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-10-20 14:49:18.921532: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-10-20 14:49:18.921548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-10-20 14:49:18.921565: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-10-20 14:49:18.921581: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-10-20 14:49:18.921598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-20 14:49:18.921652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:18.921781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:18.921864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-10-20 14:49:18.921893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-10-20 14:49:19.281633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-10-20 14:49:19.281650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-10-20 14:49:19.281656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-10-20 14:49:19.281837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:19.282013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:19.282142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-20 14:49:19.282276: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3578 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 84, 84)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 20, 20)   8224        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 9, 9)     32832       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 7, 7)     36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 8)            4104        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 8)            0           dense_3[0][0]                    \n",
      "                                                                 tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 8)            0           dense_1[0][0]                    \n",
      "                                                                 tf.math.subtract[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 3,294,889\n",
      "Trainable params: 3,294,889\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Model creation\n",
    "file_primary = Path(primary_model_file_name)\n",
    "if file_primary.exists():\n",
    "    print(\"Found an existing model\")\n",
    "    model = load_model(primary_model_file_name)\n",
    "else:\n",
    "    print(\"Model not found, a new one will be crate\")\n",
    "    model = create_dueling_model(input_shape, actions_number)\n",
    "\n",
    "# Print a summary about the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8325f-d204-47a9-84d0-e0532a453eb5",
   "metadata": {
    "id": "3cf8325f-d204-47a9-84d0-e0532a453eb5"
   },
   "source": [
    "## Training\n",
    "Here we ran the training operation. After a training session we save two plot episodes - rewards, episodes - steps. Also we save a csv with two columns: steps and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef554953-be5f-4c07-9537-7f61a548629a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32149848,
     "status": "error",
     "timestamp": 1665074725297,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "ef554953-be5f-4c07-9537-7f61a548629a",
    "outputId": "d26f332c-d658-4041-b41b-06a1d68fdd00"
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "    try:\n",
    "        model_target = create_dueling_model(input_shape, actions_number)\n",
    "        model_target.set_weights(model.get_weights())\n",
    "        optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "        policy_training = EpsilonGreedyPolicy(model, actions_number, episodes=episodes, min_epsilon=min_epsilon)\n",
    "        replay_buffer = PrioritizedExperienceReplayRankBased(buffer_size, step_to_heapify, alpha)\n",
    "        agent = DuelDQNAgent(env, model, policy_training, model_target, optimizer, replay_buffer)\n",
    "        steps, rewards = agent.double_dqn_training(batch_size, loss_function, discount_factor, freq_replacement,\n",
    "                                                   training_freq, clipping_value, beta_min, beta_max, episodes)\n",
    "\n",
    "        ext = \"png\"\n",
    "        name_plot_eps_steps = \"{} Training Episodes Steps.{}\".format(game_name, ext)\n",
    "        name_plot_eps_rewards = \"{} Training Episodes Rewards.{}\".format(game_name, ext)\n",
    "        file_plot_1 = Path(name_plot_eps_steps)\n",
    "        i = 1\n",
    "        while file_plot_1.exists():\n",
    "            i += 1\n",
    "            name_plot_eps_steps = \"{} Training Episodes Steps_{}.{}\".format(game_name, i, ext)\n",
    "            name_plot_eps_rewards = \"{} Training Episodes Rewards_{}.{}\".format(game_name, i, ext)\n",
    "            file_plot_1 = Path(name_plot_eps_steps)\n",
    "\n",
    "        plot_result(\"Episode\", \"Steps\", range(1, episodes + 1), steps, name_plot_eps_steps)\n",
    "        plot_result(\"Episode\", \"Rewards\", range(1, episodes + 1), rewards, name_plot_eps_rewards)\n",
    "\n",
    "    finally:\n",
    "        model.save(primary_model_file_name)\n",
    "\n",
    "        csv_name = \"{}.csv\".format(game_name)\n",
    "        if steps is not None and rewards is not None:\n",
    "            dict = {'steps': steps, 'rewards': rewards}\n",
    "            df = pd.DataFrame(dict)\n",
    "            df.to_csv(csv_name, mode='a', header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a05b7-819e-4b6d-ad07-bce40bd6fe01",
   "metadata": {},
   "source": [
    "# Play\n",
    "Here we play a game (one episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96580b5d-b9c7-418c-bdbe-a780b87ce2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play():\n",
    "    policy_play = EpsilonGreedyPolicy(model, actions_number, min_epsilon=min_epsilon)\n",
    "    agent = DuelDQNAgent(env, model, policy_play)\n",
    "    steps, reward = agent.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0525ad1-afdc-4a71-9bba-0041a3abad5d",
   "metadata": {
    "id": "b0525ad1-afdc-4a71-9bba-0041a3abad5d"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "vi51G7gJfU0N",
   "metadata": {
    "id": "vi51G7gJfU0N"
   },
   "outputs": [],
   "source": [
    "let_training = False# @param {type:\"boolean\"}\n",
    "let_play = True # @param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b03c22-dc33-4db8-b3e1-a4408d017e01",
   "metadata": {
    "id": "28b03c22-dc33-4db8-b3e1-a4408d017e01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-20 14:49:20.019197: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-10-20 14:49:20.530212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE number of steps: 828 reward:  20.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if let_training:\n",
    "    training()\n",
    "\n",
    "if let_play:\n",
    "    play()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NtaGEQz9kh2h",
   "metadata": {
    "id": "NtaGEQz9kh2h"
   },
   "outputs": [],
   "source": [
    "#!rm -r ./sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9-PYk6Yj2-c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1665074732809,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "b9-PYk6Yj2-c",
    "outputId": "e1565445-ca51-4d71-fee1-c565a81dda82"
   },
   "outputs": [],
   "source": [
    "#!zip -r /content/Phoenix_dueling.zip /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77KRHlFFhhNG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665074736231,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "77KRHlFFhhNG",
    "outputId": "dba6b184-6bec-447d-abef-369969bbf0ad"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#files.download('Phoenix_dueling.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
