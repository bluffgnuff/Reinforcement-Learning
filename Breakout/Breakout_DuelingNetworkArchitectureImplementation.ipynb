{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae84dfbf-263e-4d9a-ad88-2eaf271e4421",
   "metadata": {
    "id": "ae84dfbf-263e-4d9a-ad88-2eaf271e4421"
   },
   "source": [
    "# Dueling Network Architecture Implementation\n",
    "The Duelling network is an artificial neural network architecture that has improved the state of the art in the DQN area used in combination with Dual DQN and Prioritized Experience Replay. This approach splits the action value calculation using a combination of state value function and advantage function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a96bf-c613-4ec6-bf0c-0d90f01b4b8c",
   "metadata": {},
   "source": [
    "# Controls\n",
    "The flag below allows to custumize the agent behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1542dee-b62a-465a-aaec-2fcec30496e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "let_training = True # @param {type:\"boolean\"}\n",
    "let_play = False # @param {type:\"boolean\"}\n",
    "terminal_on_life_loss = True # @param {type:\"boolean\"}\n",
    "games_to_play = 30 # @param {type:\"number\"}\n",
    "rec_video = False  # @param {type:\"boolean\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8f93a-897c-4712-a81f-545e8efedc37",
   "metadata": {},
   "source": [
    "# System Setting\n",
    "The code below permits to set the system to exec the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "TDL4T4160P-8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21905,
     "status": "ok",
     "timestamp": 1665042566743,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "TDL4T4160P-8",
    "outputId": "f5f0c89a-3413-4a14-b0ac-91798038dadf"
   },
   "outputs": [],
   "source": [
    "# To setting up Google Colab\n",
    "#!pip install gym[atari,accept-rom-license]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Lab36Cm53hT3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1666077971727,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "Lab36Cm53hT3",
    "outputId": "685e3000-67fa-4bb3-e1ec-7a50773a17f0"
   },
   "outputs": [],
   "source": [
    "# !pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f1d5fad-136c-4376-b5b0-879077510380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:00:14.632370: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "/home/ste/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:00:15.807685: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-22 12:00:15.808354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-22 12:00:15.834161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:15.834288: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-11-22 12:00:15.834302: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-22 12:00:15.835699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-22 12:00:15.835730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-22 12:00:15.836959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-22 12:00:15.837157: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-22 12:00:15.838561: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-22 12:00:15.839305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-22 12:00:15.842222: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-22 12:00:15.842356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:15.842518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:15.842603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# Check that tensor flow is able to use the GPU\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc578666-0c50-4681-8b90-bc48ece391d6",
   "metadata": {
    "id": "fc578666-0c50-4681-8b90-bc48ece391d6"
   },
   "source": [
    "# Searching for available environments\n",
    "We want to test the performance of our architecture with the Atari game 'Asterix'.\n",
    "Here we check which kind of versions of this game are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82d78d38-4889-44d7-a8cd-49d3c9059bad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1539,
     "status": "ok",
     "timestamp": 1665042568266,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "82d78d38-4889-44d7-a8cd-49d3c9059bad",
    "outputId": "9d44fd58-f58f-4b95-cfa9-f00f7d2a04e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALE/Breakout-ram-v5\n",
      "ALE/Breakout-v5\n",
      "Breakout-ram-v0\n",
      "Breakout-ram-v4\n",
      "Breakout-ramDeterministic-v0\n",
      "Breakout-ramDeterministic-v4\n",
      "Breakout-ramNoFrameskip-v0\n",
      "Breakout-ramNoFrameskip-v4\n",
      "Breakout-v0\n",
      "Breakout-v4\n",
      "BreakoutDeterministic-v0\n",
      "BreakoutDeterministic-v4\n",
      "BreakoutNoFrameskip-v0\n",
      "BreakoutNoFrameskip-v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ste/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:423: UserWarning: \u001b[33mWARN: Custom namespace `ALE` is being overridden by namespace `ALE`. If you are developing a plugin you shouldn't specify a namespace in `register` calls. The namespace is specified through the entry point package metadata.\u001b[0m\n",
      "  logger.warn(\n",
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
     ]
    }
   ],
   "source": [
    "from gym import envs\n",
    "\n",
    "# Searching for available environments\n",
    "game_name = \"Breakout\"\n",
    "all_envs = envs.registry.values()\n",
    "env_ids = [env_spec.id for env_spec in all_envs]\n",
    "\n",
    "for id in sorted(env_ids):\n",
    "    if game_name in id:\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5b1aa-6e92-4ac3-9079-c49121fafaef",
   "metadata": {
    "id": "12c5b1aa-6e92-4ac3-9079-c49121fafaef"
   },
   "source": [
    "# Environment Configuration\n",
    "We select the version 4 of the environment with no frame skipping and select as render mode human. The no frame skipping is used to make this environment compatible with the optimization made by *AtariPreprocessing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cecf335-3193-4ce8-90f5-dfe1c3a82e5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1665042568266,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "3cecf335-3193-4ce8-90f5-dfe1c3a82e5f",
    "outputId": "28ea8b12-3721-41e2-a222-156e9e23bd33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.7.5+db37282)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.wrappers import AtariPreprocessing\n",
    "from gym.wrappers import FrameStack\n",
    "\n",
    "# Make Parameters:\n",
    "game_mode = \"NoFrameskip\"  # [Deterministic | NoFrameskip | ram | ramDeterministic | ramNoFrameskip ]\n",
    "game_version = \"v4\"  # [v0 | v4 | v5]\n",
    "env_name = '{}{}-{}'.format(game_name, game_mode, game_version)\n",
    "env_render_mode = 'human'  # [human | rgb_array]\n",
    "env_frame_skip = 4\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b68bf0-d09a-432b-9fe9-9991f0d8a84a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1665042568267,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "23b68bf0-d09a-432b-9fe9-9991f0d8a84a",
    "outputId": "1921b05a-a9fa-47f2-9246-26adafe63578"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0430fc5160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "env.reset() \n",
    "state = env.render(mode=\"rgb_array\")\n",
    "plt.imshow(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04326819-e929-40fe-9a26-ecfc317f7882",
   "metadata": {
    "id": "04326819-e929-40fe-9a26-ecfc317f7882"
   },
   "source": [
    "## Enviornment Observations\n",
    "Below we have a first look at the environment characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143cf671-a4e9-46a5-b06c-5f66f83fdc22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1665042568267,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "143cf671-a4e9-46a5-b06c-5f66f83fdc22",
    "outputId": "ffd6528b-5a7d-4fbf-d9e5-c4aad9150b7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "401a5ee2-bf0f-4721-be41-32c498caf4f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1665042568268,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "401a5ee2-bf0f-4721-be41-32c498caf4f3",
    "outputId": "ef5b5156-1509-47c2-98e8-2ffa96ea7495"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c5513e8-9f39-47bd-b667-a7436383795e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1665042568268,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "2c5513e8-9f39-47bd-b667-a7436383795e",
    "outputId": "f6792f4c-9ef4-485e-ef92-4875a0e28914"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad4449-5a13-4032-9645-53f78265617b",
   "metadata": {
    "id": "39ad4449-5a13-4032-9645-53f78265617b"
   },
   "source": [
    "## Environment Optimization\n",
    "We optimize the environment by adding the frame skipping, changing its observation in greyscale and following the experiment done in the paper we set to at most 30 the no-op actions; to get this we use the AtariPreprocessing wrapper.\n",
    "We use Framestack to create observations of 4 frames to give the idea of movement to the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63a89f89-355e-407a-a036-d1d14bfe3fba",
   "metadata": {
    "id": "63a89f89-355e-407a-a036-d1d14bfe3fba"
   },
   "outputs": [],
   "source": [
    "env = AtariPreprocessing(env, frame_skip=env_frame_skip, grayscale_obs=True, terminal_on_life_loss=terminal_on_life_loss, noop_max=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43876bf8-8f34-4118-990a-dba1bbbc67fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "executionInfo": {
     "elapsed": 894,
     "status": "ok",
     "timestamp": 1665042569152,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "43876bf8-8f34-4118-990a-dba1bbbc67fd",
    "outputId": "bead8004-41c7-4082-d536-f1d6bce913c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f042ee00250>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = FrameStack(env, 4)\n",
    "state = env.reset()\n",
    "_, axarr = plt.subplots(2,2, figsize=(10,10))\n",
    "axarr[0, 0].imshow(state[0])\n",
    "axarr[0, 1].imshow(state[1])\n",
    "axarr[1, 0].imshow(state[2])\n",
    "axarr[1, 1].imshow(state[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c6620c-52ee-48de-bc6b-4caba64b8f1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1665042569153,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "51c6620c-52ee-48de-bc6b-4caba64b8f1f",
    "outputId": "4c23526d-3fe5-4795-bba8-e84ad50f9222"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 84, 84)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0735fbbc-11c3-418f-8026-f3eba9dc5cb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1665042569153,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "0735fbbc-11c3-418f-8026-f3eba9dc5cb9",
    "outputId": "ce6cfa59-1f25-4917-d5c2-b5aa4a49c4c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dccc025-b2ae-48c8-a70d-0e146d5c9d7c",
   "metadata": {
    "id": "9dccc025-b2ae-48c8-a70d-0e146d5c9d7c"
   },
   "source": [
    "# Network configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579e3d9-51f6-4612-bf77-25db75a98d4a",
   "metadata": {
    "id": "e579e3d9-51f6-4612-bf77-25db75a98d4a"
   },
   "source": [
    "## Policy\n",
    "The policy is the component that chooses the action to perform; using an $\\epsilon$-gready policy the action chosen can be random with probability $\\epsilon$ or an action suggested by the ANN with probability $1 - \\epsilon$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c3213c2-3be1-4337-bf89-5a32f9dbf2c8",
   "metadata": {
    "id": "7c3213c2-3be1-4337-bf89-5a32f9dbf2c8"
   },
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class EpsilonGreedyPolicy:\n",
    "\n",
    "    def __init__(self, model, action_space_size, episodes=1, min_epsilon=0, decay_rate=1.35):\n",
    "        self.model = model\n",
    "        self.action_space_size = action_space_size\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.episode = 1\n",
    "        self.episodes = episodes\n",
    "        self.decay_rate = decay_rate\n",
    "\n",
    "    def get_action(self, state):\n",
    "        epsilon_decay = (self.episode / self.episodes)*self.decay_rate\n",
    "        epsilon = max(1 - epsilon_decay, self.min_epsilon)\n",
    "        rnd = random.random()\n",
    "        # print(random, epsilon)\n",
    "        if rnd < epsilon:\n",
    "            action = random.randint(self.action_space_size)\n",
    "            return action\n",
    "        else:\n",
    "            # Predict action Q-values\n",
    "            # From environment state\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_probs = self.model(state_tensor)\n",
    "            # Take best action\n",
    "            action = tf.argmax(action_probs[0]).numpy()\n",
    "            return action\n",
    "\n",
    "    def next_episode(self):\n",
    "        self.episode += 1\n",
    "\n",
    "    def reset_episodes(self):\n",
    "        self.episode = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255c4fef-7fd8-4e38-9eac-b7623174d588",
   "metadata": {
    "id": "255c4fef-7fd8-4e38-9eac-b7623174d588"
   },
   "source": [
    "## Replication Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f6dd9-3076-4c01-bf7f-01b9400c6fc2",
   "metadata": {
    "id": "6d9f6dd9-3076-4c01-bf7f-01b9400c6fc2"
   },
   "source": [
    "### Prioritized experience replay\n",
    "The Prioritized experience replay was introduced in the paper \"Prioritized experience replay\" (https://arxiv.org/abs/1511.05952), it consists in an evolution of the replay buffer that orders the experiences to replay by priority. In this experiment we adopt the **rank-based** variant where the experience sampling from the buffer it's done with probability $ P(i) = \\frac{p_{i}^{\\alpha}}{\\sum_k{p_{k}^{\\alpha}}} $ and $p(i)=\\frac{1}{rank(i)}$ where $rank(i)$ is the rank of the transition *i*, $\\alpha$ is called **priority exponent**. It is necessary to compute the importance sampling weights as $w_j = \\frac{(N * P(j))^{-\\beta}}{max_i{w_i}} $ and $w_i = (\\frac{1}{N} . \\frac{1}{P(i)})^\\beta$ to avoid overfitting for the experiences with more priority.\n",
    "\n",
    "In both the paper the parameters are setted as follows: **priority exponent** $\\alpha= 0.7$,  the **importance sampling exponent** $\\beta = [0.5, 1]$.\n",
    "In the paper a heap array structure is proposed to implement the buffer. Due to the particular structure and the amount of property of the replay buffer in the Prioritized Experience Replay we choose to describe it as a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e8897eb-7fea-48e8-93d4-cfd169a6278a",
   "metadata": {
    "id": "9e8897eb-7fea-48e8-93d4-cfd169a6278a"
   },
   "outputs": [],
   "source": [
    "# import heapq as heap\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import heapq\n",
    "\n",
    "class PrioritizedExperienceReplayRankBased:\n",
    "    \"\"\"\n",
    "    replay_buffer       - contains the tuples (TD_error, transaction_id, experience)\n",
    "    max_buffer_size     - it's the max size of the buffer, over which before add an experience one is remove\n",
    "    alpha               - the alpha parameter used to calculate the probability of the i-th element P(i) to be sampled\n",
    "    self.max_td_error   - max td in the buffer\n",
    "\n",
    "    Old\n",
    "    time_to_haepify - time steps before sort the structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_buffer_size, alpha):\n",
    "        self.max_buffer_size = max_buffer_size\n",
    "        # (TD, experience)\n",
    "        self.replay_buffer = []\n",
    "        self.alpha = alpha\n",
    "        # The experience added has the maximum priority but once it sampled it will be updated with a more correct\n",
    "        # value.\n",
    "        self.max_td_error = 0\n",
    "        # self.heapify_threshold = step_to_heapify  # here we stock the threshold to sort the buffer\n",
    "        # self.step_to_heapify = step_to_heapify  # number of next steps before heapify\n",
    "\n",
    "    def set_alpha(self, alpha):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    # Add experience in the buffer mapping it with its last TD_error.\n",
    "    # Heapq structure try to sort the elements of different tuple comparing from the first element of the tuple and\n",
    "    # continuing with next element until the two tuples have an element different. We are interested in sorting by TD,\n",
    "    # we don't care to sort on states, actions, or rewards. So, we use the transaction id to sort the transaction\n",
    "    # that is older in the buffer.\n",
    "    # The transaction_id of a transaction could be the -ith frame number of the whole training representing\n",
    "    # when the transaction happened.\n",
    "    # NB This approach avoids headppush fails when try to compare two states.\n",
    "    def add_experience(self, transaction_id, experience):\n",
    "        if len(self.replay_buffer) == self.max_buffer_size:\n",
    "            self.remove_experience()\n",
    "\n",
    "        # New experiences where td_error is unknown are set with the max td_error\n",
    "        if len(self.replay_buffer) > 0:\n",
    "            self.max_td_error = self.replay_buffer[0][0]\n",
    "        heapq.heappush(self.replay_buffer, (-self.max_td_error, transaction_id, experience))\n",
    "\n",
    "    # Remove experience from the buffer\n",
    "    def remove_experience(self, index=-1):\n",
    "        self.replay_buffer.pop(index)\n",
    "\n",
    "    @staticmethod\n",
    "    def zip_f_sampling(alpha, n):\n",
    "        x = np.arange(1, n + 1)\n",
    "        weights = x ** (-alpha)\n",
    "        weights /= weights.sum()\n",
    "        zipf = stats.rv_discrete(values=(x, weights))\n",
    "        return zipf.rvs() - 1\n",
    "\n",
    "    # Get batch_size samples from the buffer; using the beta parameter to compute the importance sampling weight\n",
    "    # Beta value can change while training we can delegate its control outside\n",
    "    def sample_experience(self, batch_size, beta):\n",
    "        experiences = []\n",
    "        importance_sampling_weights = []\n",
    "        n = len(self.replay_buffer) - 1\n",
    "        indexes = []\n",
    "        transaction_id = []\n",
    "\n",
    "        for i in range(0, batch_size):\n",
    "            # Sample index and check the experience is not already present in the batch\n",
    "            index = self.zip_f_sampling(self.alpha, n)\n",
    "            while index in indexes:\n",
    "                index = self.zip_f_sampling(self.alpha, n)\n",
    "            indexes.append(index)\n",
    "            # importance sampling weights computation\n",
    "            rank = index + 1\n",
    "            pj = 1 / rank\n",
    "            importance_sampling_weights.append(((n * pj) ** (-beta)))\n",
    "            transaction_id.append(self.replay_buffer[index][1])\n",
    "            experiences.append(self.replay_buffer[index][2])\n",
    "\n",
    "        # Normalization step\n",
    "        max_weight = max(importance_sampling_weights)\n",
    "        importance_sampling_weights_normalized = np.divide(importance_sampling_weights, max_weight)\n",
    "        return indexes, transaction_id, experiences, importance_sampling_weights_normalized\n",
    "\n",
    "    def update_td_error(self, indexes, td_errors):\n",
    "        # TODO update tupla e dopo ordina\n",
    "        for index, td_error in zip(indexes, td_errors):\n",
    "            my_list = list(self.replay_buffer[index])\n",
    "            my_list[0] = -abs(td_error)\n",
    "            self.replay_buffer[index] = tuple(my_list)\n",
    "        heapq.heapify(self.replay_buffer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb99df-922b-4ef1-9865-8d653c135eb8",
   "metadata": {
    "id": "5ddb99df-922b-4ef1-9865-8d653c135eb8"
   },
   "source": [
    "## Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e58cc1cd-e7dc-4f40-ba18-b5127abc5fff",
   "metadata": {
    "id": "e58cc1cd-e7dc-4f40-ba18-b5127abc5fff"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras as krs\n",
    "\n",
    "input_shape = env.observation_space.shape\n",
    "num_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d096c-c9d8-4012-9400-25075d3779cc",
   "metadata": {
    "id": "257d096c-c9d8-4012-9400-25075d3779cc"
   },
   "source": [
    "## Neural Network Creation\n",
    "The network architecture proposed follows the structure used in *\"Dueling Network Architectures for Deep Reinforcement Learning\"* https://arxiv.org/abs/1511.06581 composed of 3 convolutional layers and 2 fully connected layers for each stream (advantage, value).\n",
    "It's possible to create a dueling network using the `DQNAgent` of `rl.agents.dqn` setting `enable_dueling_network=True` in the constructor, but the purpose of this experiment is to show how to develop it manually so it is not used.\n",
    "\n",
    "The output of the value stream and the output of the advantage stream are merged to obtain the action-value function in the last module of the network using the following formula:\n",
    "$$ Q(s, a; \\theta, \\alpha, \\beta)^\\pi = V(s; \\theta, \\beta)^\\pi + (A(s, a; \\theta, \\alpha)^\\pi - \\frac{1}{|A|}\\sum_{a'}A(s, a'; \\theta, \\alpha)^\\pi) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a878b21-2040-4ca8-aeff-3563499bf9f9",
   "metadata": {
    "id": "0a878b21-2040-4ca8-aeff-3563499bf9f9"
   },
   "outputs": [],
   "source": [
    "from tensorflow import math\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "\n",
    "backend.set_image_data_format('channels_first')\n",
    "def create_dueling_model(input_shape, number_actions):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Convolutions on the frames on the screen\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "\n",
    "    value_stream_1 = layers.Dense(512)(layer4)\n",
    "    value_stream_2 = layers.Dense(1)(value_stream_1)  # scalar output size\n",
    "\n",
    "    advantage_stream_1 = layers.Dense(512)(layer4)\n",
    "    advantage_stream_2 = layers.Dense(number_actions)(advantage_stream_1)  # output size equal to the actions available\n",
    "\n",
    "    # Combination of the streams: a Q value for each state\n",
    "    q_values = value_stream_2 + math.subtract(advantage_stream_2, math.reduce_mean(advantage_stream_2, axis=1,\n",
    "                                                                                   keepdims=True))\n",
    "    # Alternative q_value\n",
    "    # q_value = value_stream_2 + (advantage_stream_2 - backend.max(advantage_stream_2, axis=1, keepdims=True))\n",
    "    return Model(inputs=[inputs], outputs=[q_values])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1b2cfe-111c-4afe-a3c5-391066124fe3",
   "metadata": {
    "id": "ff1b2cfe-111c-4afe-a3c5-391066124fe3"
   },
   "source": [
    "# Agent \n",
    "Here we define a custom agent to perfom action in the environment using a DoubleDQN training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e391a27a-28ac-4d3d-9c8f-b42bb303bd76",
   "metadata": {
    "id": "e391a27a-28ac-4d3d-9c8f-b42bb303bd76"
   },
   "source": [
    "## Play one step\n",
    "With this function we want to ask the policy what action must be chosen and perform it on the enironment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec3a88-954a-49f5-96b9-a6d34c29a16d",
   "metadata": {
    "id": "bdec3a88-954a-49f5-96b9-a6d34c29a16d"
   },
   "source": [
    "## Gradient \n",
    "In our scenario the gradient that is backpropageted to the last convolutional layer must be rescaled by $\\frac{1}{\\sqrt{2}}$. Furthermore we have to realize by hand the gradient clipping that is not realized by the optimizer since we are using a custom loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45bd489-2d61-4334-b692-51a88f5ecb29",
   "metadata": {
    "id": "c45bd489-2d61-4334-b692-51a88f5ecb29"
   },
   "source": [
    "## Double DQN Training\n",
    "Double DQN algorithm uses a second network, beyond the network used for the prediction. So in the training process the main network is used to choose an action and another to evaluate it, this permits to mitigate the overfitting present in the classic DQN. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gg9foUcDcp1r",
   "metadata": {
    "id": "gg9foUcDcp1r"
   },
   "source": [
    "## DQN Agent code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bad3e87-4bed-4e08-a34e-8a2e2fc06a83",
   "metadata": {
    "id": "6bad3e87-4bed-4e08-a34e-8a2e2fc06a83"
   },
   "outputs": [],
   "source": [
    "import math as mt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DuelDQNAgent:\n",
    "\n",
    "    # We keep the creation model outside the agent to ensure a fine-grained control on it\n",
    "    def __init__(self, env, model, policy, model_target=None, optimizer=None, replay_buffer=None):\n",
    "        self.env = env\n",
    "        self.model_primary = model\n",
    "        self.model_target = model_target\n",
    "        self.policy = policy\n",
    "        self.optimizer = optimizer\n",
    "        self.replay_buffer = replay_buffer\n",
    "\n",
    "    def set_policy(self, policy):\n",
    "        self.policy = policy\n",
    "\n",
    "    # Execs one action receiving in input the current state\n",
    "    def play_one_step(self, state):\n",
    "        action = self.policy.get_action(state)\n",
    "        # print(\"action {}\".format(action))\n",
    "        next_state, reward, done, info = self.env.step(action)\n",
    "        return action, reward, next_state, done, info\n",
    "\n",
    "    # Play\n",
    "    def play(self):\n",
    "        state = self.env.reset()\n",
    "        steps = 0\n",
    "        cumulative_reward = 0\n",
    "        while True:\n",
    "            action, reward, next_state, done, info = self.play_one_step(state)\n",
    "            cumulative_reward += reward\n",
    "            if done:\n",
    "                print(\"DONE number of steps: {} reward:  {}\".format(steps, cumulative_reward))\n",
    "                break\n",
    "            steps += 1\n",
    "            state = next_state\n",
    "        return steps, cumulative_reward\n",
    "\n",
    "    # Double DQN Training\n",
    "    #     @tf.function\n",
    "    @staticmethod\n",
    "    def gradient_clipping(gradients, clipping_value):\n",
    "        clipped_gradients = [(tf.clip_by_norm(grad, clipping_value)) for grad in gradients]\n",
    "        return clipped_gradients\n",
    "\n",
    "    #     @tf.function\n",
    "    def weighted_gradient(self, best_on_target_q_values, importance_sampling_weights, states, loss_function, mask):\n",
    "        with tf.GradientTape() as tape:\n",
    "            batch_size = len(states)\n",
    "            tape.watch(importance_sampling_weights)\n",
    "            best_on_target_q_values = tf.expand_dims(best_on_target_q_values, 1)\n",
    "            all_q_values = self.model_primary(states)\n",
    "            q_values = tf.reduce_sum(all_q_values * mask, axis=1)\n",
    "            q_values = tf.expand_dims(q_values, 1)\n",
    "            # The target and the predicted values has been expanded following the instruction in:\n",
    "            # https://www.tensorflow.org/api_docs/python/tf/compat/v1/losses/mean_squared_error\n",
    "            loss_values = loss_function(y_true=best_on_target_q_values, y_pred=q_values,\n",
    "                                        sample_weight=importance_sampling_weights)\n",
    "            loss_value = tf.reduce_sum(loss_values) / batch_size\n",
    "\n",
    "        grads = tape.gradient(loss_value, self.model_primary.trainable_variables)\n",
    "        return grads, loss_values.numpy()\n",
    "\n",
    "    @staticmethod\n",
    "    def rescale_grad(gradients, rescale_value, index):\n",
    "        tensor_to_scale = gradients[index]\n",
    "        rescaled_tensor = tensor_to_scale * rescale_value\n",
    "        gradients[index] = rescaled_tensor\n",
    "        return gradients\n",
    "\n",
    "    # Collects samples of the previous experiences from the replay buffer\n",
    "    # and use them to improve the weights update of the Neural Network.\n",
    "    def double_dqn_training_step(self, batch_size, loss_function, discount_factor, clipping_value, beta, step_size=1):\n",
    "        indexes, transaction_ids, experiences, importance_sampling_weights = self.replay_buffer.sample_experience(\n",
    "            batch_size, beta)\n",
    "        states, actions, rewards, next_states, dones = [np.array([experience[field_index] for experience in experiences]\n",
    "                                                                 ) for field_index in range(5)]\n",
    "\n",
    "        action_space = self.env.action_space.n\n",
    "        # Predict using the primary network\n",
    "        next_q_values = self.model_primary.predict(next_states)\n",
    "        next_q_values_target = self.model_target.predict(next_states)\n",
    "\n",
    "        # Select the action that lead us to the higher next Q value\n",
    "        best_actions = np.argmax(next_q_values, axis=1)\n",
    "        best_action_mask = tf.one_hot(best_actions, action_space)\n",
    "\n",
    "        next_q_value_target = tf.reduce_sum(next_q_values_target * best_action_mask, axis=1)\n",
    "        best_on_target_q_values = (rewards + (1 - dones) * discount_factor * next_q_value_target)\n",
    "        # Punishment\n",
    "        best_on_target_q_values = best_on_target_q_values * (1-dones) - (dones)\n",
    "\n",
    "        mask = tf.one_hot(actions, action_space)\n",
    "        importance_sampling_weights = tf.convert_to_tensor(importance_sampling_weights, tf.float32)\n",
    "        weighted_gradient, loss_values = self.weighted_gradient(best_on_target_q_values, importance_sampling_weights,\n",
    "                                                                states, loss_function, mask)\n",
    "        self.replay_buffer.update_td_error(indexes, loss_values)\n",
    "\n",
    "        # We rescale the last convolutional layer to 1/sqrt(2) to balance the double backpropagation\n",
    "        # The index of the last sequential layer\n",
    "        rescale_value = (1 / mt.sqrt(2))\n",
    "        index_gradient_to_rescale = 4\n",
    "        rescaled_grads = self.rescale_grad(weighted_gradient, rescale_value, index_gradient_to_rescale)\n",
    "\n",
    "        # Since we are in a custom loop we have to clip the gradient by hand, we can't delegate it to the optimizer\n",
    "        clipped_gradients = self.gradient_clipping(rescaled_grads, clipping_value)\n",
    "        # Application gradient descent trough optimizer\n",
    "        self.optimizer.apply_gradients(zip(clipped_gradients, self.model_primary.trainable_variables))\n",
    "\n",
    "    # We use the training step just when there is enough samples on the replay buffer\n",
    "    def double_dqn_training(self, batch_size, loss_function, discount_factor, freq_replacement, training_freq,\n",
    "                            clipping_value, beta_min, beta_max, max_episodes=600, max_steps=10800):\n",
    "        rewards_stock = []\n",
    "        steps_stock = []\n",
    "        cumulative_steps = 0\n",
    "\n",
    "        for episode in range(1, max_episodes + 1):\n",
    "            state = self.env.reset()\n",
    "            rewards = 0\n",
    "            steps = 0\n",
    "            beta = max(beta_min, (beta_max * episode / max_episodes))\n",
    "\n",
    "            while True:\n",
    "                action, reward, next_state, done, info = self.play_one_step(state)\n",
    "                experience = [state, action, reward, next_state, done]\n",
    "                rewards += reward\n",
    "                self.replay_buffer.add_experience(cumulative_steps, experience)\n",
    "                cumulative_steps += 1\n",
    "                steps += 1\n",
    "\n",
    "                if len(self.replay_buffer.replay_buffer) > batch_size and (cumulative_steps % training_freq) == 0:\n",
    "                    self.double_dqn_training_step(batch_size, loss_function, discount_factor, clipping_value, beta)\n",
    "                if (cumulative_steps % freq_replacement) == 0:\n",
    "                    self.model_target.set_weights(self.model_primary.get_weights())\n",
    "                if steps == max_steps:\n",
    "                    print(\n",
    "                        \"ABORTED episode = {} number of steps = {} reward = {}\".format(episode, steps, rewards))\n",
    "                if done:\n",
    "                    print(\n",
    "                        \"DONE episode = {} number of steps = {} reward = {}\".format(episode, steps, rewards))\n",
    "                if done or steps == max_steps:\n",
    "                    rewards_stock.append(rewards)\n",
    "                    steps_stock.append(steps)\n",
    "                    break\n",
    "                state = next_state\n",
    "\n",
    "            self.policy.next_episode()\n",
    "\n",
    "        return steps_stock, rewards_stock\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538fe86-67f4-4292-b80c-0225a088b271",
   "metadata": {
    "id": "9538fe86-67f4-4292-b80c-0225a088b271"
   },
   "source": [
    "## Result plots\n",
    "We use this function to generate the plot representing the rewards or the steps for each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ef6ec3d-002c-4d30-9052-4e05db6839a0",
   "metadata": {
    "id": "6ef6ec3d-002c-4d30-9052-4e05db6839a0"
   },
   "outputs": [],
   "source": [
    "def plot_result(x_label, y_label, x, y, name):\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.plot(x, y)\n",
    "    plt.savefig(name)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364dba26-35cc-4d53-878a-6bf0496b5a24",
   "metadata": {
    "id": "364dba26-35cc-4d53-878a-6bf0496b5a24"
   },
   "source": [
    "# Training\n",
    "The learning step is executed with the **Double Deep Q-networks** algorithm presented in the paper *\"Deep reinforcement learning with double Q-learning\"*.https://arxiv.org/pdf/1509.06461.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e16f49-345d-460c-922d-f529d9291a07",
   "metadata": {
    "id": "23e16f49-345d-460c-922d-f529d9291a07"
   },
   "source": [
    "## Training parameters\n",
    "We adopt as optimizer the **Adam** implementation setting the learning rate equal to $6.25x10^{-5}$ and **clipping the gradient** norm at most to 10; the parameters are specified in the paper \"*Deep reinforcement learning with double Q-learning*\" (https://arxiv.org/pdf/1509.06461.pdf)\n",
    "To evaluate the loss score we use the `mean_squared_error`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4742cf2f-c7c6-403e-9da9-32d47e7717da",
   "metadata": {
    "id": "4742cf2f-c7c6-403e-9da9-32d47e7717da"
   },
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Environment info\n",
    "input_shape = env.observation_space.shape\n",
    "actions_number = env.action_space.n\n",
    "\n",
    "# Model persistent file\n",
    "primary_model_file_name = \"{}_dueling_model\".format(game_name)\n",
    "\n",
    "# Training Parameters\n",
    "loss_function = losses.MeanSquaredError(reduction=losses.Reduction.NONE)\n",
    "batch_size = 32 # @param {type:\"integer\"}\n",
    "discount_factor = 0.95 # @param {type:\"number\"}\n",
    "learning_rate = 6.25e-5 # @param {type:\"number\"}\n",
    "episodes = 10000 # @param {type:\"integer\"}\n",
    "clipping_value = 10 # @param {type:\"number\"}\n",
    "training_freq = 4 # @param {type:\"integer\"}\n",
    "\n",
    "# Dual DQN Training\n",
    "freq_replacement = 1000 # @param {type:\"integer\"}\n",
    "\n",
    "# Replay buffer parameters\n",
    "buffer_size = 100000 # @param {type:\"integer\"}\n",
    "# step_to_heapify = 200 # @param {type:\"integer\"}\n",
    "alpha = 0.7 # @param {type:\"number\"}\n",
    "beta_max = 1 # @param {type:\"number\"}\n",
    "beta_min = 0.5 # @param {type:\"number\"}\n",
    "\n",
    "# Policy parameters\n",
    "min_epsilon = 0.01 # @param {type:\"number\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf7e90-0940-497c-8dc3-cafa5366bc3f",
   "metadata": {
    "id": "5fbf7e90-0940-497c-8dc3-cafa5366bc3f"
   },
   "source": [
    "## Model creation / loading \n",
    "In this step we check whether there is an already saved model and load it in that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44e76e0d-1130-47d8-b055-dbaa73907926",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3653,
     "status": "ok",
     "timestamp": 1665042575453,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "44e76e0d-1130-47d8-b055-dbaa73907926",
    "outputId": "49ca5eb3-67e4-44d7-a61a-02e830afe86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not found, a new one will be crate\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 4, 84, 84)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 20, 20)   8224        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 9, 9)     32832       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 7, 7)     36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3136)         0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            2052        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1606144     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 1)            0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            513         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 4)            0           dense_3[0][0]                    \n",
      "                                                                 tf.math.reduce_mean[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 4)            0           dense_1[0][0]                    \n",
      "                                                                 tf.math.subtract[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 3,292,837\n",
      "Trainable params: 3,292,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:00:17.664993: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 12:00:17.665524: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-11-22 12:00:17.665712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:17.665848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1050 Ti computeCapability: 6.1\n",
      "coreClock: 1.4175GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s\n",
      "2022-11-22 12:00:17.665878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-22 12:00:17.665913: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-22 12:00:17.665924: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-11-22 12:00:17.665935: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-11-22 12:00:17.665946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-11-22 12:00:17.665957: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-11-22 12:00:17.665968: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-11-22 12:00:17.665979: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-22 12:00:17.666041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:17.666162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:17.666247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-11-22 12:00:17.666823: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-11-22 12:00:18.702354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-22 12:00:18.702377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-11-22 12:00:18.702385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-11-22 12:00:18.702941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:18.703109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:18.703241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 12:00:18.703348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3474 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Model creation\n",
    "file_primary = Path(primary_model_file_name)\n",
    "if file_primary.exists():\n",
    "    print(\"Found an existing model\")\n",
    "    model = load_model(primary_model_file_name)\n",
    "else:\n",
    "    print(\"Model not found, a new one will be crate\")\n",
    "    model = create_dueling_model(input_shape, actions_number)\n",
    "\n",
    "# Print a summary about the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8325f-d204-47a9-84d0-e0532a453eb5",
   "metadata": {
    "id": "3cf8325f-d204-47a9-84d0-e0532a453eb5"
   },
   "source": [
    "## Training\n",
    "Here we ran the training operation. After a training session we save two plot episodes - rewards, episodes - steps. Also we save a csv with two columns: steps and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef554953-be5f-4c07-9537-7f61a548629a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32149848,
     "status": "error",
     "timestamp": 1665074725297,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "ef554953-be5f-4c07-9537-7f61a548629a",
    "outputId": "d26f332c-d658-4041-b41b-06a1d68fdd00"
   },
   "outputs": [],
   "source": [
    "def training():\n",
    "    try:\n",
    "        model_target = create_dueling_model(input_shape, actions_number)\n",
    "        model_target.set_weights(model.get_weights())\n",
    "        optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
    "        policy_training = EpsilonGreedyPolicy(model, actions_number, episodes=episodes, min_epsilon=min_epsilon)\n",
    "        replay_buffer = PrioritizedExperienceReplayRankBased(buffer_size, alpha)\n",
    "        agent = DuelDQNAgent(env, model, policy_training, model_target, optimizer, replay_buffer)\n",
    "        steps, rewards = agent.double_dqn_training(batch_size, loss_function, discount_factor, freq_replacement,\n",
    "                                                   training_freq, clipping_value, beta_min, beta_max, episodes)\n",
    "\n",
    "        ext = \"png\"\n",
    "        name_plot_eps_steps = \"{} Training Episodes Steps.{}\".format(game_name, ext)\n",
    "        name_plot_eps_rewards = \"{} Training Episodes Rewards.{}\".format(game_name, ext)\n",
    "        file_plot_1 = Path(name_plot_eps_steps)\n",
    "        i = 1\n",
    "        while file_plot_1.exists():\n",
    "            i += 1\n",
    "            name_plot_eps_steps = \"{} Training Episodes Steps_{}.{}\".format(game_name, i, ext)\n",
    "            name_plot_eps_rewards = \"{} Training Episodes Rewards_{}.{}\".format(game_name, i, ext)\n",
    "            file_plot_1 = Path(name_plot_eps_steps)\n",
    "\n",
    "        plot_result(\"Episode\", \"Steps\", range(1, episodes + 1), steps, name_plot_eps_steps)\n",
    "        plot_result(\"Episode\", \"Rewards\", range(1, episodes + 1), rewards, name_plot_eps_rewards)\n",
    "\n",
    "        csv_name = \"{}.csv\".format(game_name)\n",
    "        dict = {'steps': steps, 'rewards': rewards}\n",
    "        df = pd.DataFrame(dict)\n",
    "        df.to_csv(csv_name, mode='a', header=False)\n",
    "\n",
    "    finally:\n",
    "        model.save(primary_model_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a05b7-819e-4b6d-ad07-bce40bd6fe01",
   "metadata": {},
   "source": [
    "# Play\n",
    "Here we play a game (one episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96580b5d-b9c7-418c-bdbe-a780b87ce2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play():    \n",
    "    policy_play = EpsilonGreedyPolicy(model, actions_number, min_epsilon=min_epsilon)\n",
    "    agent = DuelDQNAgent(env, model, policy_play)\n",
    "    steps, reward = agent.play()\n",
    "    return reward, steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0525ad1-afdc-4a71-9bba-0041a3abad5d",
   "metadata": {
    "id": "b0525ad1-afdc-4a71-9bba-0041a3abad5d"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b03c22-dc33-4db8-b3e1-a4408d017e01",
   "metadata": {
    "id": "28b03c22-dc33-4db8-b3e1-a4408d017e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE episode = 1 number of steps = 25 reward = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 12:00:19.055459: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-11-22 12:00:19.075084: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200660000 Hz\n",
      "2022-11-22 12:00:19.158504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-11-22 12:00:19.479574: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE episode = 2 number of steps = 73 reward = 1.0\n",
      "DONE episode = 3 number of steps = 28 reward = 0.0\n",
      "DONE episode = 4 number of steps = 25 reward = 0.0\n",
      "DONE episode = 5 number of steps = 25 reward = 0.0\n",
      "DONE episode = 6 number of steps = 25 reward = 0.0\n",
      "DONE episode = 7 number of steps = 27 reward = 0.0\n",
      "DONE episode = 8 number of steps = 27 reward = 0.0\n",
      "DONE episode = 9 number of steps = 32 reward = 0.0\n",
      "DONE episode = 10 number of steps = 100 reward = 2.0\n",
      "DONE episode = 11 number of steps = 102 reward = 2.0\n",
      "DONE episode = 12 number of steps = 27 reward = 0.0\n",
      "DONE episode = 13 number of steps = 26 reward = 0.0\n",
      "DONE episode = 14 number of steps = 26 reward = 0.0\n",
      "DONE episode = 15 number of steps = 29 reward = 0.0\n",
      "DONE episode = 16 number of steps = 26 reward = 0.0\n",
      "DONE episode = 17 number of steps = 25 reward = 0.0\n",
      "DONE episode = 18 number of steps = 29 reward = 0.0\n",
      "DONE episode = 19 number of steps = 33 reward = 0.0\n",
      "DONE episode = 20 number of steps = 54 reward = 1.0\n",
      "DONE episode = 21 number of steps = 74 reward = 1.0\n",
      "DONE episode = 22 number of steps = 25 reward = 0.0\n",
      "DONE episode = 23 number of steps = 28 reward = 0.0\n",
      "DONE episode = 24 number of steps = 72 reward = 1.0\n",
      "DONE episode = 25 number of steps = 25 reward = 0.0\n",
      "DONE episode = 26 number of steps = 34 reward = 0.0\n",
      "DONE episode = 27 number of steps = 29 reward = 0.0\n",
      "DONE episode = 28 number of steps = 25 reward = 0.0\n",
      "DONE episode = 29 number of steps = 28 reward = 0.0\n",
      "DONE episode = 30 number of steps = 25 reward = 0.0\n",
      "DONE episode = 31 number of steps = 53 reward = 1.0\n",
      "DONE episode = 32 number of steps = 27 reward = 0.0\n",
      "DONE episode = 33 number of steps = 74 reward = 1.0\n",
      "DONE episode = 34 number of steps = 32 reward = 0.0\n",
      "DONE episode = 35 number of steps = 34 reward = 0.0\n",
      "DONE episode = 36 number of steps = 29 reward = 0.0\n",
      "DONE episode = 37 number of steps = 30 reward = 0.0\n",
      "DONE episode = 38 number of steps = 31 reward = 0.0\n",
      "DONE episode = 39 number of steps = 25 reward = 0.0\n",
      "DONE episode = 40 number of steps = 28 reward = 0.0\n",
      "DONE episode = 41 number of steps = 28 reward = 0.0\n",
      "DONE episode = 42 number of steps = 29 reward = 0.0\n",
      "DONE episode = 43 number of steps = 42 reward = 0.0\n",
      "DONE episode = 44 number of steps = 26 reward = 0.0\n",
      "DONE episode = 45 number of steps = 33 reward = 0.0\n",
      "DONE episode = 46 number of steps = 27 reward = 0.0\n",
      "DONE episode = 47 number of steps = 26 reward = 0.0\n",
      "DONE episode = 48 number of steps = 101 reward = 2.0\n",
      "DONE episode = 49 number of steps = 26 reward = 0.0\n",
      "DONE episode = 50 number of steps = 25 reward = 0.0\n",
      "DONE episode = 51 number of steps = 27 reward = 0.0\n",
      "DONE episode = 52 number of steps = 26 reward = 0.0\n",
      "DONE episode = 53 number of steps = 26 reward = 0.0\n",
      "DONE episode = 54 number of steps = 28 reward = 0.0\n",
      "DONE episode = 55 number of steps = 26 reward = 0.0\n",
      "DONE episode = 56 number of steps = 30 reward = 0.0\n",
      "DONE episode = 57 number of steps = 27 reward = 0.0\n",
      "DONE episode = 58 number of steps = 72 reward = 1.0\n",
      "DONE episode = 59 number of steps = 29 reward = 0.0\n",
      "DONE episode = 60 number of steps = 31 reward = 0.0\n",
      "DONE episode = 61 number of steps = 26 reward = 0.0\n",
      "DONE episode = 62 number of steps = 61 reward = 1.0\n",
      "DONE episode = 63 number of steps = 25 reward = 0.0\n",
      "DONE episode = 64 number of steps = 56 reward = 1.0\n",
      "DONE episode = 65 number of steps = 25 reward = 0.0\n",
      "DONE episode = 66 number of steps = 25 reward = 0.0\n",
      "DONE episode = 67 number of steps = 54 reward = 1.0\n",
      "DONE episode = 68 number of steps = 25 reward = 0.0\n",
      "DONE episode = 69 number of steps = 25 reward = 0.0\n",
      "DONE episode = 70 number of steps = 27 reward = 0.0\n",
      "DONE episode = 71 number of steps = 26 reward = 0.0\n",
      "DONE episode = 72 number of steps = 32 reward = 0.0\n",
      "DONE episode = 73 number of steps = 53 reward = 1.0\n",
      "DONE episode = 74 number of steps = 26 reward = 0.0\n",
      "DONE episode = 75 number of steps = 28 reward = 0.0\n",
      "DONE episode = 76 number of steps = 57 reward = 1.0\n",
      "DONE episode = 77 number of steps = 25 reward = 0.0\n",
      "DONE episode = 78 number of steps = 25 reward = 0.0\n",
      "DONE episode = 79 number of steps = 37 reward = 0.0\n",
      "DONE episode = 80 number of steps = 28 reward = 0.0\n",
      "DONE episode = 81 number of steps = 25 reward = 0.0\n",
      "DONE episode = 82 number of steps = 31 reward = 0.0\n",
      "DONE episode = 83 number of steps = 26 reward = 0.0\n",
      "DONE episode = 84 number of steps = 26 reward = 0.0\n",
      "DONE episode = 85 number of steps = 29 reward = 0.0\n",
      "DONE episode = 86 number of steps = 72 reward = 1.0\n",
      "DONE episode = 87 number of steps = 25 reward = 0.0\n",
      "DONE episode = 88 number of steps = 29 reward = 0.0\n",
      "DONE episode = 89 number of steps = 53 reward = 1.0\n",
      "DONE episode = 90 number of steps = 27 reward = 0.0\n",
      "DONE episode = 91 number of steps = 31 reward = 0.0\n",
      "DONE episode = 92 number of steps = 26 reward = 0.0\n",
      "DONE episode = 93 number of steps = 25 reward = 0.0\n",
      "DONE episode = 94 number of steps = 28 reward = 0.0\n",
      "DONE episode = 95 number of steps = 27 reward = 0.0\n",
      "DONE episode = 96 number of steps = 25 reward = 0.0\n",
      "DONE episode = 97 number of steps = 34 reward = 0.0\n",
      "DONE episode = 98 number of steps = 26 reward = 0.0\n",
      "DONE episode = 99 number of steps = 27 reward = 0.0\n",
      "DONE episode = 100 number of steps = 53 reward = 1.0\n",
      "DONE episode = 101 number of steps = 26 reward = 0.0\n",
      "DONE episode = 102 number of steps = 28 reward = 0.0\n",
      "DONE episode = 103 number of steps = 31 reward = 0.0\n",
      "DONE episode = 104 number of steps = 31 reward = 0.0\n",
      "DONE episode = 105 number of steps = 25 reward = 0.0\n",
      "DONE episode = 106 number of steps = 30 reward = 0.0\n",
      "DONE episode = 107 number of steps = 55 reward = 1.0\n",
      "DONE episode = 108 number of steps = 25 reward = 0.0\n",
      "DONE episode = 109 number of steps = 27 reward = 0.0\n",
      "DONE episode = 110 number of steps = 29 reward = 0.0\n",
      "DONE episode = 111 number of steps = 28 reward = 0.0\n",
      "DONE episode = 112 number of steps = 27 reward = 0.0\n",
      "DONE episode = 113 number of steps = 30 reward = 0.0\n",
      "DONE episode = 114 number of steps = 121 reward = 2.0\n",
      "DONE episode = 115 number of steps = 71 reward = 1.0\n",
      "DONE episode = 116 number of steps = 30 reward = 0.0\n",
      "DONE episode = 117 number of steps = 25 reward = 0.0\n",
      "DONE episode = 118 number of steps = 25 reward = 0.0\n",
      "DONE episode = 119 number of steps = 59 reward = 1.0\n",
      "DONE episode = 120 number of steps = 26 reward = 0.0\n",
      "DONE episode = 121 number of steps = 30 reward = 0.0\n",
      "DONE episode = 122 number of steps = 28 reward = 0.0\n",
      "DONE episode = 123 number of steps = 103 reward = 2.0\n",
      "DONE episode = 124 number of steps = 29 reward = 0.0\n",
      "DONE episode = 125 number of steps = 25 reward = 0.0\n",
      "DONE episode = 126 number of steps = 119 reward = 2.0\n",
      "DONE episode = 127 number of steps = 56 reward = 1.0\n",
      "DONE episode = 128 number of steps = 25 reward = 0.0\n",
      "DONE episode = 129 number of steps = 27 reward = 0.0\n",
      "DONE episode = 130 number of steps = 29 reward = 0.0\n",
      "DONE episode = 131 number of steps = 101 reward = 2.0\n",
      "DONE episode = 132 number of steps = 27 reward = 0.0\n",
      "DONE episode = 133 number of steps = 26 reward = 0.0\n",
      "DONE episode = 134 number of steps = 27 reward = 0.0\n",
      "DONE episode = 135 number of steps = 123 reward = 2.0\n",
      "DONE episode = 136 number of steps = 60 reward = 1.0\n",
      "DONE episode = 137 number of steps = 74 reward = 1.0\n",
      "DONE episode = 138 number of steps = 29 reward = 0.0\n",
      "DONE episode = 139 number of steps = 58 reward = 1.0\n",
      "DONE episode = 140 number of steps = 36 reward = 0.0\n",
      "DONE episode = 141 number of steps = 26 reward = 0.0\n",
      "DONE episode = 142 number of steps = 55 reward = 1.0\n",
      "DONE episode = 143 number of steps = 55 reward = 1.0\n",
      "DONE episode = 144 number of steps = 44 reward = 0.0\n",
      "DONE episode = 145 number of steps = 75 reward = 1.0\n",
      "DONE episode = 146 number of steps = 31 reward = 0.0\n",
      "DONE episode = 147 number of steps = 34 reward = 0.0\n",
      "DONE episode = 148 number of steps = 35 reward = 0.0\n",
      "DONE episode = 149 number of steps = 25 reward = 0.0\n",
      "DONE episode = 150 number of steps = 26 reward = 0.0\n",
      "DONE episode = 151 number of steps = 128 reward = 2.0\n",
      "DONE episode = 152 number of steps = 28 reward = 0.0\n",
      "DONE episode = 153 number of steps = 30 reward = 0.0\n",
      "DONE episode = 154 number of steps = 25 reward = 0.0\n",
      "DONE episode = 155 number of steps = 26 reward = 0.0\n",
      "DONE episode = 156 number of steps = 100 reward = 2.0\n",
      "DONE episode = 157 number of steps = 73 reward = 1.0\n",
      "DONE episode = 158 number of steps = 87 reward = 2.0\n",
      "DONE episode = 159 number of steps = 25 reward = 0.0\n",
      "DONE episode = 160 number of steps = 56 reward = 1.0\n",
      "DONE episode = 161 number of steps = 29 reward = 0.0\n",
      "DONE episode = 162 number of steps = 139 reward = 3.0\n",
      "DONE episode = 163 number of steps = 25 reward = 0.0\n",
      "DONE episode = 164 number of steps = 121 reward = 2.0\n",
      "DONE episode = 165 number of steps = 26 reward = 0.0\n",
      "DONE episode = 166 number of steps = 31 reward = 0.0\n",
      "DONE episode = 167 number of steps = 58 reward = 1.0\n",
      "DONE episode = 168 number of steps = 27 reward = 0.0\n",
      "DONE episode = 169 number of steps = 81 reward = 1.0\n",
      "DONE episode = 170 number of steps = 25 reward = 0.0\n",
      "DONE episode = 171 number of steps = 25 reward = 0.0\n",
      "DONE episode = 172 number of steps = 30 reward = 0.0\n",
      "DONE episode = 173 number of steps = 32 reward = 0.0\n",
      "DONE episode = 174 number of steps = 33 reward = 0.0\n",
      "DONE episode = 175 number of steps = 29 reward = 0.0\n",
      "DONE episode = 176 number of steps = 33 reward = 0.0\n",
      "DONE episode = 177 number of steps = 25 reward = 0.0\n",
      "DONE episode = 178 number of steps = 25 reward = 0.0\n",
      "DONE episode = 179 number of steps = 33 reward = 0.0\n",
      "DONE episode = 180 number of steps = 34 reward = 0.0\n",
      "DONE episode = 181 number of steps = 27 reward = 0.0\n",
      "DONE episode = 182 number of steps = 26 reward = 0.0\n",
      "DONE episode = 183 number of steps = 29 reward = 0.0\n",
      "DONE episode = 184 number of steps = 102 reward = 2.0\n",
      "DONE episode = 185 number of steps = 26 reward = 0.0\n",
      "DONE episode = 186 number of steps = 28 reward = 0.0\n",
      "DONE episode = 187 number of steps = 34 reward = 0.0\n",
      "DONE episode = 188 number of steps = 25 reward = 0.0\n",
      "DONE episode = 189 number of steps = 25 reward = 0.0\n",
      "DONE episode = 190 number of steps = 25 reward = 0.0\n",
      "DONE episode = 191 number of steps = 60 reward = 1.0\n",
      "DONE episode = 192 number of steps = 57 reward = 1.0\n",
      "DONE episode = 193 number of steps = 71 reward = 1.0\n",
      "DONE episode = 194 number of steps = 30 reward = 0.0\n",
      "DONE episode = 195 number of steps = 25 reward = 0.0\n",
      "DONE episode = 196 number of steps = 74 reward = 1.0\n",
      "DONE episode = 197 number of steps = 32 reward = 0.0\n",
      "DONE episode = 198 number of steps = 25 reward = 0.0\n",
      "DONE episode = 199 number of steps = 57 reward = 1.0\n",
      "DONE episode = 200 number of steps = 106 reward = 2.0\n",
      "DONE episode = 201 number of steps = 25 reward = 0.0\n",
      "DONE episode = 202 number of steps = 36 reward = 0.0\n",
      "DONE episode = 203 number of steps = 25 reward = 0.0\n",
      "DONE episode = 204 number of steps = 38 reward = 0.0\n",
      "DONE episode = 205 number of steps = 25 reward = 0.0\n",
      "DONE episode = 206 number of steps = 26 reward = 0.0\n",
      "DONE episode = 207 number of steps = 31 reward = 0.0\n",
      "DONE episode = 208 number of steps = 25 reward = 0.0\n",
      "DONE episode = 209 number of steps = 29 reward = 0.0\n",
      "DONE episode = 210 number of steps = 84 reward = 2.0\n",
      "DONE episode = 211 number of steps = 54 reward = 1.0\n",
      "DONE episode = 212 number of steps = 57 reward = 1.0\n",
      "DONE episode = 213 number of steps = 28 reward = 0.0\n",
      "DONE episode = 214 number of steps = 125 reward = 2.0\n",
      "DONE episode = 215 number of steps = 27 reward = 0.0\n",
      "DONE episode = 216 number of steps = 30 reward = 0.0\n",
      "DONE episode = 217 number of steps = 101 reward = 2.0\n",
      "DONE episode = 218 number of steps = 25 reward = 0.0\n",
      "DONE episode = 219 number of steps = 26 reward = 0.0\n",
      "DONE episode = 220 number of steps = 30 reward = 0.0\n",
      "DONE episode = 221 number of steps = 31 reward = 0.0\n",
      "DONE episode = 222 number of steps = 133 reward = 3.0\n",
      "DONE episode = 223 number of steps = 38 reward = 0.0\n",
      "DONE episode = 224 number of steps = 31 reward = 0.0\n",
      "DONE episode = 225 number of steps = 25 reward = 0.0\n",
      "DONE episode = 226 number of steps = 29 reward = 0.0\n",
      "DONE episode = 227 number of steps = 36 reward = 0.0\n",
      "DONE episode = 228 number of steps = 25 reward = 0.0\n",
      "DONE episode = 229 number of steps = 39 reward = 0.0\n",
      "DONE episode = 230 number of steps = 85 reward = 1.0\n",
      "DONE episode = 231 number of steps = 25 reward = 0.0\n",
      "DONE episode = 232 number of steps = 25 reward = 0.0\n",
      "DONE episode = 233 number of steps = 72 reward = 1.0\n",
      "DONE episode = 234 number of steps = 27 reward = 0.0\n",
      "DONE episode = 235 number of steps = 78 reward = 1.0\n",
      "DONE episode = 236 number of steps = 153 reward = 3.0\n",
      "DONE episode = 237 number of steps = 27 reward = 0.0\n",
      "DONE episode = 238 number of steps = 25 reward = 0.0\n",
      "DONE episode = 239 number of steps = 26 reward = 0.0\n",
      "DONE episode = 240 number of steps = 26 reward = 0.0\n",
      "DONE episode = 241 number of steps = 25 reward = 0.0\n",
      "DONE episode = 242 number of steps = 34 reward = 0.0\n",
      "DONE episode = 243 number of steps = 103 reward = 2.0\n",
      "DONE episode = 244 number of steps = 38 reward = 0.0\n",
      "DONE episode = 245 number of steps = 26 reward = 0.0\n",
      "DONE episode = 246 number of steps = 53 reward = 1.0\n",
      "DONE episode = 247 number of steps = 29 reward = 0.0\n",
      "DONE episode = 248 number of steps = 25 reward = 0.0\n",
      "DONE episode = 249 number of steps = 26 reward = 0.0\n",
      "DONE episode = 250 number of steps = 61 reward = 1.0\n",
      "DONE episode = 251 number of steps = 30 reward = 0.0\n",
      "DONE episode = 252 number of steps = 29 reward = 0.0\n",
      "DONE episode = 253 number of steps = 43 reward = 0.0\n",
      "DONE episode = 254 number of steps = 27 reward = 0.0\n",
      "DONE episode = 255 number of steps = 34 reward = 0.0\n",
      "DONE episode = 256 number of steps = 30 reward = 0.0\n",
      "DONE episode = 257 number of steps = 25 reward = 0.0\n",
      "DONE episode = 258 number of steps = 26 reward = 0.0\n",
      "DONE episode = 259 number of steps = 32 reward = 0.0\n",
      "DONE episode = 260 number of steps = 28 reward = 0.0\n",
      "DONE episode = 261 number of steps = 153 reward = 3.0\n",
      "DONE episode = 262 number of steps = 33 reward = 0.0\n",
      "DONE episode = 263 number of steps = 28 reward = 0.0\n",
      "DONE episode = 264 number of steps = 26 reward = 0.0\n",
      "DONE episode = 265 number of steps = 49 reward = 0.0\n",
      "DONE episode = 266 number of steps = 36 reward = 0.0\n",
      "DONE episode = 267 number of steps = 28 reward = 0.0\n",
      "DONE episode = 268 number of steps = 25 reward = 0.0\n",
      "DONE episode = 269 number of steps = 39 reward = 0.0\n",
      "DONE episode = 270 number of steps = 31 reward = 0.0\n",
      "DONE episode = 271 number of steps = 32 reward = 0.0\n",
      "DONE episode = 272 number of steps = 80 reward = 1.0\n",
      "DONE episode = 273 number of steps = 74 reward = 1.0\n",
      "DONE episode = 274 number of steps = 53 reward = 1.0\n",
      "DONE episode = 275 number of steps = 25 reward = 0.0\n",
      "DONE episode = 276 number of steps = 25 reward = 0.0\n",
      "DONE episode = 277 number of steps = 30 reward = 0.0\n",
      "DONE episode = 278 number of steps = 29 reward = 0.0\n",
      "DONE episode = 279 number of steps = 30 reward = 0.0\n",
      "DONE episode = 280 number of steps = 100 reward = 2.0\n",
      "DONE episode = 281 number of steps = 56 reward = 1.0\n",
      "DONE episode = 282 number of steps = 26 reward = 0.0\n",
      "DONE episode = 283 number of steps = 43 reward = 0.0\n",
      "DONE episode = 284 number of steps = 30 reward = 0.0\n",
      "DONE episode = 285 number of steps = 100 reward = 2.0\n",
      "DONE episode = 286 number of steps = 29 reward = 0.0\n",
      "DONE episode = 287 number of steps = 27 reward = 0.0\n",
      "DONE episode = 288 number of steps = 26 reward = 0.0\n",
      "DONE episode = 289 number of steps = 25 reward = 0.0\n",
      "DONE episode = 290 number of steps = 29 reward = 0.0\n",
      "DONE episode = 291 number of steps = 30 reward = 0.0\n",
      "DONE episode = 292 number of steps = 25 reward = 0.0\n",
      "DONE episode = 293 number of steps = 30 reward = 0.0\n",
      "DONE episode = 294 number of steps = 28 reward = 0.0\n",
      "DONE episode = 295 number of steps = 27 reward = 0.0\n",
      "DONE episode = 296 number of steps = 26 reward = 0.0\n",
      "DONE episode = 297 number of steps = 26 reward = 0.0\n",
      "DONE episode = 298 number of steps = 29 reward = 0.0\n",
      "DONE episode = 299 number of steps = 27 reward = 0.0\n",
      "DONE episode = 300 number of steps = 26 reward = 0.0\n",
      "DONE episode = 301 number of steps = 28 reward = 0.0\n",
      "DONE episode = 302 number of steps = 27 reward = 0.0\n",
      "DONE episode = 303 number of steps = 25 reward = 0.0\n",
      "DONE episode = 304 number of steps = 39 reward = 0.0\n",
      "DONE episode = 305 number of steps = 105 reward = 2.0\n",
      "DONE episode = 306 number of steps = 76 reward = 1.0\n",
      "DONE episode = 307 number of steps = 55 reward = 1.0\n",
      "DONE episode = 308 number of steps = 30 reward = 0.0\n",
      "DONE episode = 309 number of steps = 58 reward = 1.0\n",
      "DONE episode = 310 number of steps = 75 reward = 1.0\n",
      "DONE episode = 311 number of steps = 102 reward = 2.0\n",
      "DONE episode = 312 number of steps = 122 reward = 2.0\n",
      "DONE episode = 313 number of steps = 55 reward = 1.0\n",
      "DONE episode = 314 number of steps = 103 reward = 2.0\n",
      "DONE episode = 315 number of steps = 28 reward = 0.0\n",
      "DONE episode = 316 number of steps = 28 reward = 0.0\n",
      "DONE episode = 317 number of steps = 27 reward = 0.0\n",
      "DONE episode = 318 number of steps = 32 reward = 0.0\n",
      "DONE episode = 319 number of steps = 86 reward = 2.0\n",
      "DONE episode = 320 number of steps = 34 reward = 0.0\n",
      "DONE episode = 321 number of steps = 26 reward = 0.0\n",
      "DONE episode = 322 number of steps = 72 reward = 1.0\n",
      "DONE episode = 323 number of steps = 27 reward = 0.0\n",
      "DONE episode = 324 number of steps = 30 reward = 0.0\n",
      "DONE episode = 325 number of steps = 25 reward = 0.0\n",
      "DONE episode = 326 number of steps = 27 reward = 0.0\n",
      "DONE episode = 327 number of steps = 32 reward = 0.0\n",
      "DONE episode = 328 number of steps = 25 reward = 0.0\n",
      "DONE episode = 329 number of steps = 31 reward = 0.0\n",
      "DONE episode = 330 number of steps = 73 reward = 1.0\n",
      "DONE episode = 331 number of steps = 124 reward = 2.0\n",
      "DONE episode = 332 number of steps = 28 reward = 0.0\n",
      "DONE episode = 333 number of steps = 32 reward = 0.0\n",
      "DONE episode = 334 number of steps = 25 reward = 0.0\n",
      "DONE episode = 335 number of steps = 25 reward = 0.0\n",
      "DONE episode = 336 number of steps = 25 reward = 0.0\n",
      "DONE episode = 337 number of steps = 28 reward = 0.0\n",
      "DONE episode = 338 number of steps = 31 reward = 0.0\n",
      "DONE episode = 339 number of steps = 25 reward = 0.0\n",
      "DONE episode = 340 number of steps = 26 reward = 0.0\n",
      "DONE episode = 341 number of steps = 26 reward = 0.0\n",
      "DONE episode = 342 number of steps = 25 reward = 0.0\n",
      "DONE episode = 343 number of steps = 26 reward = 0.0\n",
      "DONE episode = 344 number of steps = 37 reward = 0.0\n",
      "DONE episode = 345 number of steps = 27 reward = 0.0\n",
      "DONE episode = 346 number of steps = 25 reward = 0.0\n",
      "DONE episode = 347 number of steps = 76 reward = 1.0\n",
      "DONE episode = 348 number of steps = 31 reward = 0.0\n",
      "DONE episode = 349 number of steps = 109 reward = 2.0\n",
      "DONE episode = 350 number of steps = 33 reward = 0.0\n",
      "DONE episode = 351 number of steps = 25 reward = 0.0\n",
      "DONE episode = 352 number of steps = 55 reward = 1.0\n",
      "DONE episode = 353 number of steps = 25 reward = 0.0\n",
      "DONE episode = 354 number of steps = 27 reward = 0.0\n",
      "DONE episode = 355 number of steps = 54 reward = 1.0\n",
      "DONE episode = 356 number of steps = 27 reward = 0.0\n",
      "DONE episode = 357 number of steps = 26 reward = 0.0\n",
      "DONE episode = 358 number of steps = 29 reward = 0.0\n",
      "DONE episode = 359 number of steps = 71 reward = 1.0\n",
      "DONE episode = 360 number of steps = 27 reward = 0.0\n",
      "DONE episode = 361 number of steps = 73 reward = 1.0\n",
      "DONE episode = 362 number of steps = 29 reward = 0.0\n",
      "DONE episode = 363 number of steps = 25 reward = 0.0\n",
      "DONE episode = 364 number of steps = 33 reward = 0.0\n",
      "DONE episode = 365 number of steps = 27 reward = 0.0\n",
      "DONE episode = 366 number of steps = 28 reward = 0.0\n",
      "DONE episode = 367 number of steps = 52 reward = 0.0\n",
      "DONE episode = 368 number of steps = 25 reward = 0.0\n",
      "DONE episode = 369 number of steps = 25 reward = 0.0\n",
      "DONE episode = 370 number of steps = 27 reward = 0.0\n",
      "DONE episode = 371 number of steps = 25 reward = 0.0\n",
      "DONE episode = 372 number of steps = 25 reward = 0.0\n",
      "DONE episode = 373 number of steps = 28 reward = 0.0\n",
      "DONE episode = 374 number of steps = 37 reward = 0.0\n",
      "DONE episode = 375 number of steps = 35 reward = 0.0\n",
      "DONE episode = 376 number of steps = 125 reward = 2.0\n",
      "DONE episode = 377 number of steps = 26 reward = 0.0\n",
      "DONE episode = 378 number of steps = 71 reward = 1.0\n",
      "DONE episode = 379 number of steps = 26 reward = 0.0\n",
      "DONE episode = 380 number of steps = 26 reward = 0.0\n",
      "DONE episode = 381 number of steps = 26 reward = 0.0\n",
      "DONE episode = 382 number of steps = 25 reward = 0.0\n",
      "DONE episode = 383 number of steps = 35 reward = 0.0\n",
      "DONE episode = 384 number of steps = 27 reward = 0.0\n",
      "DONE episode = 385 number of steps = 32 reward = 0.0\n",
      "DONE episode = 386 number of steps = 25 reward = 0.0\n",
      "DONE episode = 387 number of steps = 127 reward = 2.0\n",
      "DONE episode = 388 number of steps = 25 reward = 0.0\n",
      "DONE episode = 389 number of steps = 26 reward = 0.0\n",
      "DONE episode = 390 number of steps = 34 reward = 0.0\n",
      "DONE episode = 391 number of steps = 38 reward = 0.0\n",
      "DONE episode = 392 number of steps = 34 reward = 0.0\n",
      "DONE episode = 393 number of steps = 28 reward = 0.0\n",
      "DONE episode = 394 number of steps = 32 reward = 0.0\n",
      "DONE episode = 395 number of steps = 25 reward = 0.0\n",
      "DONE episode = 396 number of steps = 25 reward = 0.0\n",
      "DONE episode = 397 number of steps = 26 reward = 0.0\n",
      "DONE episode = 398 number of steps = 26 reward = 0.0\n",
      "DONE episode = 399 number of steps = 31 reward = 0.0\n",
      "DONE episode = 400 number of steps = 30 reward = 0.0\n",
      "DONE episode = 401 number of steps = 28 reward = 0.0\n",
      "DONE episode = 402 number of steps = 25 reward = 0.0\n",
      "DONE episode = 403 number of steps = 53 reward = 1.0\n",
      "DONE episode = 404 number of steps = 27 reward = 0.0\n",
      "DONE episode = 405 number of steps = 26 reward = 0.0\n",
      "DONE episode = 406 number of steps = 25 reward = 0.0\n",
      "DONE episode = 407 number of steps = 28 reward = 0.0\n",
      "DONE episode = 408 number of steps = 25 reward = 0.0\n",
      "DONE episode = 409 number of steps = 27 reward = 0.0\n",
      "DONE episode = 410 number of steps = 29 reward = 0.0\n",
      "DONE episode = 411 number of steps = 40 reward = 0.0\n",
      "DONE episode = 412 number of steps = 25 reward = 0.0\n",
      "DONE episode = 413 number of steps = 29 reward = 0.0\n",
      "DONE episode = 414 number of steps = 26 reward = 0.0\n",
      "DONE episode = 415 number of steps = 27 reward = 0.0\n",
      "DONE episode = 416 number of steps = 77 reward = 1.0\n",
      "DONE episode = 417 number of steps = 32 reward = 0.0\n",
      "DONE episode = 418 number of steps = 40 reward = 0.0\n",
      "DONE episode = 419 number of steps = 26 reward = 0.0\n",
      "DONE episode = 420 number of steps = 27 reward = 0.0\n",
      "DONE episode = 421 number of steps = 122 reward = 2.0\n",
      "DONE episode = 422 number of steps = 27 reward = 0.0\n",
      "DONE episode = 423 number of steps = 25 reward = 0.0\n",
      "DONE episode = 424 number of steps = 28 reward = 0.0\n",
      "DONE episode = 425 number of steps = 57 reward = 1.0\n",
      "DONE episode = 426 number of steps = 28 reward = 0.0\n",
      "DONE episode = 427 number of steps = 35 reward = 0.0\n",
      "DONE episode = 428 number of steps = 36 reward = 0.0\n",
      "DONE episode = 429 number of steps = 25 reward = 0.0\n",
      "DONE episode = 430 number of steps = 25 reward = 0.0\n",
      "DONE episode = 431 number of steps = 31 reward = 0.0\n",
      "DONE episode = 432 number of steps = 45 reward = 0.0\n",
      "DONE episode = 433 number of steps = 37 reward = 0.0\n",
      "DONE episode = 434 number of steps = 27 reward = 0.0\n",
      "DONE episode = 435 number of steps = 25 reward = 0.0\n",
      "DONE episode = 436 number of steps = 29 reward = 0.0\n",
      "DONE episode = 437 number of steps = 30 reward = 0.0\n",
      "DONE episode = 438 number of steps = 45 reward = 0.0\n",
      "DONE episode = 439 number of steps = 37 reward = 0.0\n",
      "DONE episode = 440 number of steps = 26 reward = 0.0\n",
      "DONE episode = 441 number of steps = 27 reward = 0.0\n",
      "DONE episode = 442 number of steps = 25 reward = 0.0\n",
      "DONE episode = 443 number of steps = 26 reward = 0.0\n",
      "DONE episode = 444 number of steps = 28 reward = 0.0\n",
      "DONE episode = 445 number of steps = 41 reward = 0.0\n",
      "DONE episode = 446 number of steps = 25 reward = 0.0\n",
      "DONE episode = 447 number of steps = 27 reward = 0.0\n",
      "DONE episode = 448 number of steps = 29 reward = 0.0\n",
      "DONE episode = 449 number of steps = 32 reward = 0.0\n",
      "DONE episode = 450 number of steps = 75 reward = 1.0\n",
      "DONE episode = 451 number of steps = 33 reward = 0.0\n",
      "DONE episode = 452 number of steps = 26 reward = 0.0\n",
      "DONE episode = 453 number of steps = 25 reward = 0.0\n",
      "DONE episode = 454 number of steps = 76 reward = 1.0\n",
      "DONE episode = 455 number of steps = 28 reward = 0.0\n",
      "DONE episode = 456 number of steps = 33 reward = 0.0\n",
      "DONE episode = 457 number of steps = 33 reward = 0.0\n",
      "DONE episode = 458 number of steps = 29 reward = 0.0\n",
      "DONE episode = 459 number of steps = 25 reward = 0.0\n",
      "DONE episode = 460 number of steps = 60 reward = 0.0\n",
      "DONE episode = 461 number of steps = 27 reward = 0.0\n",
      "DONE episode = 462 number of steps = 56 reward = 1.0\n",
      "DONE episode = 463 number of steps = 59 reward = 1.0\n",
      "DONE episode = 464 number of steps = 28 reward = 0.0\n",
      "DONE episode = 465 number of steps = 72 reward = 1.0\n",
      "DONE episode = 466 number of steps = 29 reward = 0.0\n",
      "DONE episode = 467 number of steps = 34 reward = 0.0\n",
      "DONE episode = 468 number of steps = 59 reward = 1.0\n",
      "DONE episode = 469 number of steps = 29 reward = 0.0\n",
      "DONE episode = 470 number of steps = 34 reward = 0.0\n",
      "DONE episode = 471 number of steps = 30 reward = 0.0\n",
      "DONE episode = 472 number of steps = 58 reward = 1.0\n",
      "DONE episode = 473 number of steps = 31 reward = 0.0\n",
      "DONE episode = 474 number of steps = 25 reward = 0.0\n",
      "DONE episode = 475 number of steps = 33 reward = 0.0\n",
      "DONE episode = 476 number of steps = 105 reward = 2.0\n",
      "DONE episode = 477 number of steps = 25 reward = 0.0\n",
      "DONE episode = 478 number of steps = 104 reward = 2.0\n",
      "DONE episode = 479 number of steps = 28 reward = 0.0\n",
      "DONE episode = 480 number of steps = 76 reward = 1.0\n",
      "DONE episode = 481 number of steps = 109 reward = 2.0\n",
      "DONE episode = 482 number of steps = 129 reward = 2.0\n",
      "DONE episode = 483 number of steps = 45 reward = 0.0\n",
      "DONE episode = 484 number of steps = 72 reward = 1.0\n",
      "DONE episode = 485 number of steps = 36 reward = 0.0\n",
      "DONE episode = 486 number of steps = 31 reward = 0.0\n",
      "DONE episode = 487 number of steps = 64 reward = 1.0\n",
      "DONE episode = 488 number of steps = 30 reward = 0.0\n",
      "DONE episode = 489 number of steps = 27 reward = 0.0\n",
      "DONE episode = 490 number of steps = 33 reward = 0.0\n",
      "DONE episode = 491 number of steps = 25 reward = 0.0\n",
      "DONE episode = 492 number of steps = 25 reward = 0.0\n",
      "DONE episode = 493 number of steps = 38 reward = 0.0\n",
      "DONE episode = 494 number of steps = 28 reward = 0.0\n",
      "DONE episode = 495 number of steps = 33 reward = 0.0\n",
      "DONE episode = 496 number of steps = 36 reward = 0.0\n",
      "DONE episode = 497 number of steps = 53 reward = 1.0\n",
      "DONE episode = 498 number of steps = 30 reward = 0.0\n",
      "DONE episode = 499 number of steps = 151 reward = 3.0\n",
      "DONE episode = 500 number of steps = 27 reward = 0.0\n",
      "DONE episode = 501 number of steps = 60 reward = 1.0\n",
      "DONE episode = 502 number of steps = 25 reward = 0.0\n",
      "DONE episode = 503 number of steps = 25 reward = 0.0\n",
      "DONE episode = 504 number of steps = 28 reward = 0.0\n",
      "DONE episode = 505 number of steps = 26 reward = 0.0\n",
      "DONE episode = 506 number of steps = 59 reward = 1.0\n",
      "DONE episode = 507 number of steps = 124 reward = 2.0\n",
      "DONE episode = 508 number of steps = 27 reward = 0.0\n",
      "DONE episode = 509 number of steps = 26 reward = 0.0\n",
      "DONE episode = 510 number of steps = 26 reward = 0.0\n",
      "DONE episode = 511 number of steps = 27 reward = 0.0\n",
      "DONE episode = 512 number of steps = 27 reward = 0.0\n",
      "DONE episode = 513 number of steps = 25 reward = 0.0\n",
      "DONE episode = 514 number of steps = 38 reward = 0.0\n",
      "DONE episode = 515 number of steps = 33 reward = 0.0\n",
      "DONE episode = 516 number of steps = 31 reward = 0.0\n",
      "DONE episode = 517 number of steps = 25 reward = 0.0\n",
      "DONE episode = 518 number of steps = 34 reward = 0.0\n",
      "DONE episode = 519 number of steps = 79 reward = 1.0\n",
      "DONE episode = 520 number of steps = 25 reward = 0.0\n",
      "DONE episode = 521 number of steps = 30 reward = 0.0\n",
      "DONE episode = 522 number of steps = 34 reward = 0.0\n",
      "DONE episode = 523 number of steps = 34 reward = 0.0\n",
      "DONE episode = 524 number of steps = 30 reward = 0.0\n",
      "DONE episode = 525 number of steps = 27 reward = 0.0\n",
      "DONE episode = 526 number of steps = 39 reward = 0.0\n",
      "DONE episode = 527 number of steps = 27 reward = 0.0\n",
      "DONE episode = 528 number of steps = 27 reward = 0.0\n",
      "DONE episode = 529 number of steps = 28 reward = 0.0\n",
      "DONE episode = 530 number of steps = 33 reward = 0.0\n",
      "DONE episode = 531 number of steps = 28 reward = 0.0\n",
      "DONE episode = 532 number of steps = 27 reward = 0.0\n",
      "DONE episode = 533 number of steps = 26 reward = 0.0\n",
      "DONE episode = 534 number of steps = 28 reward = 0.0\n",
      "DONE episode = 535 number of steps = 42 reward = 0.0\n",
      "DONE episode = 536 number of steps = 60 reward = 1.0\n",
      "DONE episode = 537 number of steps = 62 reward = 1.0\n",
      "DONE episode = 538 number of steps = 87 reward = 2.0\n",
      "DONE episode = 539 number of steps = 31 reward = 0.0\n",
      "DONE episode = 540 number of steps = 31 reward = 0.0\n",
      "DONE episode = 541 number of steps = 33 reward = 0.0\n",
      "DONE episode = 542 number of steps = 27 reward = 0.0\n",
      "DONE episode = 543 number of steps = 41 reward = 0.0\n",
      "DONE episode = 544 number of steps = 26 reward = 0.0\n",
      "DONE episode = 545 number of steps = 25 reward = 0.0\n",
      "DONE episode = 546 number of steps = 43 reward = 0.0\n",
      "DONE episode = 547 number of steps = 31 reward = 0.0\n",
      "DONE episode = 548 number of steps = 29 reward = 0.0\n",
      "DONE episode = 549 number of steps = 56 reward = 1.0\n",
      "DONE episode = 550 number of steps = 109 reward = 2.0\n",
      "DONE episode = 551 number of steps = 26 reward = 0.0\n",
      "DONE episode = 552 number of steps = 37 reward = 0.0\n",
      "DONE episode = 553 number of steps = 27 reward = 0.0\n",
      "DONE episode = 554 number of steps = 25 reward = 0.0\n",
      "DONE episode = 555 number of steps = 39 reward = 0.0\n",
      "DONE episode = 556 number of steps = 47 reward = 0.0\n",
      "DONE episode = 557 number of steps = 28 reward = 0.0\n",
      "DONE episode = 558 number of steps = 34 reward = 0.0\n",
      "DONE episode = 559 number of steps = 34 reward = 0.0\n",
      "DONE episode = 560 number of steps = 25 reward = 0.0\n",
      "DONE episode = 561 number of steps = 33 reward = 0.0\n",
      "DONE episode = 562 number of steps = 28 reward = 0.0\n",
      "DONE episode = 563 number of steps = 27 reward = 0.0\n",
      "DONE episode = 564 number of steps = 27 reward = 0.0\n",
      "DONE episode = 565 number of steps = 30 reward = 0.0\n",
      "DONE episode = 566 number of steps = 55 reward = 1.0\n",
      "DONE episode = 567 number of steps = 55 reward = 1.0\n",
      "DONE episode = 568 number of steps = 77 reward = 1.0\n",
      "DONE episode = 569 number of steps = 29 reward = 0.0\n",
      "DONE episode = 570 number of steps = 53 reward = 1.0\n",
      "DONE episode = 571 number of steps = 29 reward = 0.0\n",
      "DONE episode = 572 number of steps = 72 reward = 1.0\n",
      "DONE episode = 573 number of steps = 27 reward = 0.0\n",
      "DONE episode = 574 number of steps = 25 reward = 0.0\n",
      "DONE episode = 575 number of steps = 26 reward = 0.0\n",
      "DONE episode = 576 number of steps = 56 reward = 1.0\n",
      "DONE episode = 577 number of steps = 30 reward = 0.0\n",
      "DONE episode = 578 number of steps = 26 reward = 0.0\n",
      "DONE episode = 579 number of steps = 102 reward = 2.0\n",
      "DONE episode = 580 number of steps = 36 reward = 0.0\n",
      "DONE episode = 581 number of steps = 26 reward = 0.0\n",
      "DONE episode = 582 number of steps = 25 reward = 0.0\n",
      "DONE episode = 583 number of steps = 26 reward = 0.0\n",
      "DONE episode = 584 number of steps = 29 reward = 0.0\n",
      "DONE episode = 585 number of steps = 59 reward = 1.0\n",
      "DONE episode = 586 number of steps = 119 reward = 2.0\n",
      "DONE episode = 587 number of steps = 26 reward = 0.0\n",
      "DONE episode = 588 number of steps = 25 reward = 0.0\n",
      "DONE episode = 589 number of steps = 25 reward = 0.0\n",
      "DONE episode = 590 number of steps = 26 reward = 0.0\n",
      "DONE episode = 591 number of steps = 25 reward = 0.0\n",
      "DONE episode = 592 number of steps = 55 reward = 1.0\n",
      "DONE episode = 593 number of steps = 32 reward = 0.0\n",
      "DONE episode = 594 number of steps = 27 reward = 0.0\n",
      "DONE episode = 595 number of steps = 27 reward = 0.0\n",
      "DONE episode = 596 number of steps = 31 reward = 0.0\n",
      "DONE episode = 597 number of steps = 26 reward = 0.0\n",
      "DONE episode = 598 number of steps = 28 reward = 0.0\n",
      "DONE episode = 599 number of steps = 28 reward = 0.0\n",
      "DONE episode = 600 number of steps = 29 reward = 0.0\n",
      "DONE episode = 601 number of steps = 29 reward = 0.0\n",
      "DONE episode = 602 number of steps = 26 reward = 0.0\n",
      "DONE episode = 603 number of steps = 53 reward = 1.0\n",
      "DONE episode = 604 number of steps = 28 reward = 0.0\n",
      "DONE episode = 605 number of steps = 74 reward = 1.0\n",
      "DONE episode = 606 number of steps = 25 reward = 0.0\n",
      "DONE episode = 607 number of steps = 43 reward = 0.0\n",
      "DONE episode = 608 number of steps = 57 reward = 1.0\n",
      "DONE episode = 609 number of steps = 25 reward = 0.0\n",
      "DONE episode = 610 number of steps = 25 reward = 0.0\n",
      "DONE episode = 611 number of steps = 26 reward = 0.0\n",
      "DONE episode = 612 number of steps = 25 reward = 0.0\n",
      "DONE episode = 613 number of steps = 27 reward = 0.0\n",
      "DONE episode = 614 number of steps = 27 reward = 0.0\n",
      "DONE episode = 615 number of steps = 27 reward = 0.0\n",
      "DONE episode = 616 number of steps = 34 reward = 0.0\n",
      "DONE episode = 617 number of steps = 33 reward = 0.0\n",
      "DONE episode = 618 number of steps = 27 reward = 0.0\n",
      "DONE episode = 619 number of steps = 27 reward = 0.0\n",
      "DONE episode = 620 number of steps = 53 reward = 1.0\n",
      "DONE episode = 621 number of steps = 27 reward = 0.0\n",
      "DONE episode = 622 number of steps = 33 reward = 0.0\n",
      "DONE episode = 623 number of steps = 25 reward = 0.0\n",
      "DONE episode = 624 number of steps = 56 reward = 1.0\n",
      "DONE episode = 625 number of steps = 25 reward = 0.0\n",
      "DONE episode = 626 number of steps = 28 reward = 0.0\n",
      "DONE episode = 627 number of steps = 25 reward = 0.0\n",
      "DONE episode = 628 number of steps = 27 reward = 0.0\n",
      "DONE episode = 629 number of steps = 25 reward = 0.0\n",
      "DONE episode = 630 number of steps = 26 reward = 0.0\n",
      "DONE episode = 631 number of steps = 25 reward = 0.0\n",
      "DONE episode = 632 number of steps = 103 reward = 2.0\n",
      "DONE episode = 633 number of steps = 26 reward = 0.0\n",
      "DONE episode = 634 number of steps = 25 reward = 0.0\n",
      "DONE episode = 635 number of steps = 41 reward = 0.0\n",
      "DONE episode = 636 number of steps = 30 reward = 0.0\n",
      "DONE episode = 637 number of steps = 28 reward = 0.0\n",
      "DONE episode = 638 number of steps = 27 reward = 0.0\n",
      "DONE episode = 639 number of steps = 26 reward = 0.0\n",
      "DONE episode = 640 number of steps = 33 reward = 0.0\n",
      "DONE episode = 641 number of steps = 31 reward = 0.0\n",
      "DONE episode = 642 number of steps = 56 reward = 1.0\n",
      "DONE episode = 643 number of steps = 26 reward = 0.0\n",
      "DONE episode = 644 number of steps = 34 reward = 0.0\n",
      "DONE episode = 645 number of steps = 25 reward = 0.0\n",
      "DONE episode = 646 number of steps = 28 reward = 0.0\n",
      "DONE episode = 647 number of steps = 25 reward = 0.0\n",
      "DONE episode = 648 number of steps = 74 reward = 1.0\n",
      "DONE episode = 649 number of steps = 27 reward = 0.0\n",
      "DONE episode = 650 number of steps = 59 reward = 1.0\n",
      "DONE episode = 651 number of steps = 66 reward = 1.0\n",
      "DONE episode = 652 number of steps = 33 reward = 0.0\n",
      "DONE episode = 653 number of steps = 26 reward = 0.0\n",
      "DONE episode = 654 number of steps = 26 reward = 0.0\n",
      "DONE episode = 655 number of steps = 34 reward = 0.0\n",
      "DONE episode = 656 number of steps = 71 reward = 1.0\n",
      "DONE episode = 657 number of steps = 26 reward = 0.0\n",
      "DONE episode = 658 number of steps = 54 reward = 1.0\n",
      "DONE episode = 659 number of steps = 36 reward = 0.0\n",
      "DONE episode = 660 number of steps = 27 reward = 0.0\n",
      "DONE episode = 661 number of steps = 72 reward = 1.0\n",
      "DONE episode = 662 number of steps = 75 reward = 1.0\n",
      "DONE episode = 663 number of steps = 27 reward = 0.0\n",
      "DONE episode = 664 number of steps = 25 reward = 0.0\n",
      "DONE episode = 665 number of steps = 28 reward = 0.0\n",
      "DONE episode = 666 number of steps = 26 reward = 0.0\n",
      "DONE episode = 667 number of steps = 29 reward = 0.0\n",
      "DONE episode = 668 number of steps = 26 reward = 0.0\n",
      "DONE episode = 669 number of steps = 25 reward = 0.0\n",
      "DONE episode = 670 number of steps = 30 reward = 0.0\n",
      "DONE episode = 671 number of steps = 25 reward = 0.0\n",
      "DONE episode = 672 number of steps = 25 reward = 0.0\n",
      "DONE episode = 673 number of steps = 56 reward = 1.0\n",
      "DONE episode = 674 number of steps = 25 reward = 0.0\n",
      "DONE episode = 675 number of steps = 25 reward = 0.0\n",
      "DONE episode = 676 number of steps = 25 reward = 0.0\n",
      "DONE episode = 677 number of steps = 29 reward = 0.0\n",
      "DONE episode = 678 number of steps = 25 reward = 0.0\n",
      "DONE episode = 679 number of steps = 136 reward = 3.0\n",
      "DONE episode = 680 number of steps = 76 reward = 1.0\n",
      "DONE episode = 681 number of steps = 54 reward = 1.0\n",
      "DONE episode = 682 number of steps = 27 reward = 0.0\n",
      "DONE episode = 683 number of steps = 55 reward = 1.0\n",
      "DONE episode = 684 number of steps = 137 reward = 3.0\n",
      "DONE episode = 685 number of steps = 53 reward = 1.0\n",
      "DONE episode = 686 number of steps = 25 reward = 0.0\n",
      "DONE episode = 687 number of steps = 36 reward = 0.0\n",
      "DONE episode = 688 number of steps = 25 reward = 0.0\n",
      "DONE episode = 689 number of steps = 40 reward = 0.0\n",
      "DONE episode = 690 number of steps = 54 reward = 1.0\n",
      "DONE episode = 691 number of steps = 31 reward = 0.0\n",
      "DONE episode = 692 number of steps = 25 reward = 0.0\n",
      "DONE episode = 693 number of steps = 26 reward = 0.0\n",
      "DONE episode = 694 number of steps = 25 reward = 0.0\n",
      "DONE episode = 695 number of steps = 71 reward = 1.0\n",
      "DONE episode = 696 number of steps = 90 reward = 2.0\n",
      "DONE episode = 697 number of steps = 25 reward = 0.0\n",
      "DONE episode = 698 number of steps = 34 reward = 0.0\n",
      "DONE episode = 699 number of steps = 25 reward = 0.0\n",
      "DONE episode = 700 number of steps = 25 reward = 0.0\n",
      "DONE episode = 701 number of steps = 76 reward = 1.0\n",
      "DONE episode = 702 number of steps = 25 reward = 0.0\n",
      "DONE episode = 703 number of steps = 25 reward = 0.0\n",
      "DONE episode = 704 number of steps = 54 reward = 1.0\n",
      "DONE episode = 705 number of steps = 25 reward = 0.0\n",
      "DONE episode = 706 number of steps = 25 reward = 0.0\n",
      "DONE episode = 707 number of steps = 29 reward = 0.0\n",
      "DONE episode = 708 number of steps = 53 reward = 1.0\n",
      "DONE episode = 709 number of steps = 29 reward = 0.0\n",
      "DONE episode = 710 number of steps = 26 reward = 0.0\n",
      "DONE episode = 711 number of steps = 26 reward = 0.0\n",
      "DONE episode = 712 number of steps = 25 reward = 0.0\n",
      "DONE episode = 713 number of steps = 30 reward = 0.0\n",
      "DONE episode = 714 number of steps = 29 reward = 0.0\n",
      "DONE episode = 715 number of steps = 26 reward = 0.0\n",
      "DONE episode = 716 number of steps = 26 reward = 0.0\n",
      "DONE episode = 717 number of steps = 26 reward = 0.0\n",
      "DONE episode = 718 number of steps = 32 reward = 0.0\n",
      "DONE episode = 719 number of steps = 32 reward = 0.0\n",
      "DONE episode = 720 number of steps = 26 reward = 0.0\n",
      "DONE episode = 721 number of steps = 26 reward = 0.0\n",
      "DONE episode = 722 number of steps = 73 reward = 1.0\n",
      "DONE episode = 723 number of steps = 25 reward = 0.0\n",
      "DONE episode = 724 number of steps = 26 reward = 0.0\n",
      "DONE episode = 725 number of steps = 25 reward = 0.0\n",
      "DONE episode = 726 number of steps = 71 reward = 1.0\n",
      "DONE episode = 727 number of steps = 25 reward = 0.0\n",
      "DONE episode = 728 number of steps = 27 reward = 0.0\n",
      "DONE episode = 729 number of steps = 27 reward = 0.0\n",
      "DONE episode = 730 number of steps = 25 reward = 0.0\n",
      "DONE episode = 731 number of steps = 25 reward = 0.0\n",
      "DONE episode = 732 number of steps = 25 reward = 0.0\n",
      "DONE episode = 733 number of steps = 27 reward = 0.0\n",
      "DONE episode = 734 number of steps = 71 reward = 1.0\n",
      "DONE episode = 735 number of steps = 25 reward = 0.0\n",
      "DONE episode = 736 number of steps = 25 reward = 0.0\n",
      "DONE episode = 737 number of steps = 25 reward = 0.0\n",
      "DONE episode = 738 number of steps = 32 reward = 0.0\n",
      "DONE episode = 739 number of steps = 27 reward = 0.0\n",
      "DONE episode = 740 number of steps = 25 reward = 0.0\n",
      "DONE episode = 741 number of steps = 25 reward = 0.0\n",
      "DONE episode = 742 number of steps = 71 reward = 1.0\n",
      "DONE episode = 743 number of steps = 26 reward = 0.0\n",
      "DONE episode = 744 number of steps = 26 reward = 0.0\n",
      "DONE episode = 745 number of steps = 25 reward = 0.0\n",
      "DONE episode = 746 number of steps = 71 reward = 1.0\n",
      "DONE episode = 747 number of steps = 26 reward = 0.0\n",
      "DONE episode = 748 number of steps = 26 reward = 0.0\n",
      "DONE episode = 749 number of steps = 25 reward = 0.0\n",
      "DONE episode = 750 number of steps = 26 reward = 0.0\n",
      "DONE episode = 751 number of steps = 25 reward = 0.0\n",
      "DONE episode = 752 number of steps = 25 reward = 0.0\n",
      "DONE episode = 753 number of steps = 26 reward = 0.0\n",
      "DONE episode = 754 number of steps = 25 reward = 0.0\n",
      "DONE episode = 755 number of steps = 25 reward = 0.0\n",
      "DONE episode = 756 number of steps = 25 reward = 0.0\n",
      "DONE episode = 757 number of steps = 74 reward = 1.0\n",
      "DONE episode = 758 number of steps = 25 reward = 0.0\n",
      "DONE episode = 759 number of steps = 26 reward = 0.0\n",
      "DONE episode = 760 number of steps = 25 reward = 0.0\n",
      "DONE episode = 761 number of steps = 25 reward = 0.0\n",
      "DONE episode = 762 number of steps = 27 reward = 0.0\n",
      "DONE episode = 763 number of steps = 26 reward = 0.0\n",
      "DONE episode = 764 number of steps = 25 reward = 0.0\n",
      "DONE episode = 765 number of steps = 26 reward = 0.0\n",
      "DONE episode = 766 number of steps = 101 reward = 2.0\n",
      "DONE episode = 767 number of steps = 29 reward = 0.0\n",
      "DONE episode = 768 number of steps = 27 reward = 0.0\n",
      "DONE episode = 769 number of steps = 25 reward = 0.0\n",
      "DONE episode = 770 number of steps = 53 reward = 1.0\n",
      "DONE episode = 771 number of steps = 25 reward = 0.0\n",
      "DONE episode = 772 number of steps = 25 reward = 0.0\n",
      "DONE episode = 773 number of steps = 72 reward = 1.0\n",
      "DONE episode = 774 number of steps = 26 reward = 0.0\n",
      "DONE episode = 775 number of steps = 25 reward = 0.0\n",
      "DONE episode = 776 number of steps = 26 reward = 0.0\n",
      "DONE episode = 777 number of steps = 26 reward = 0.0\n",
      "DONE episode = 778 number of steps = 90 reward = 2.0\n",
      "DONE episode = 779 number of steps = 25 reward = 0.0\n",
      "DONE episode = 780 number of steps = 25 reward = 0.0\n",
      "DONE episode = 781 number of steps = 100 reward = 2.0\n",
      "DONE episode = 782 number of steps = 27 reward = 0.0\n",
      "DONE episode = 783 number of steps = 26 reward = 0.0\n",
      "DONE episode = 784 number of steps = 25 reward = 0.0\n",
      "DONE episode = 785 number of steps = 25 reward = 0.0\n",
      "DONE episode = 786 number of steps = 25 reward = 0.0\n",
      "DONE episode = 787 number of steps = 25 reward = 0.0\n",
      "DONE episode = 788 number of steps = 28 reward = 0.0\n",
      "DONE episode = 789 number of steps = 55 reward = 1.0\n",
      "DONE episode = 790 number of steps = 25 reward = 0.0\n",
      "DONE episode = 791 number of steps = 25 reward = 0.0\n",
      "DONE episode = 792 number of steps = 30 reward = 0.0\n",
      "DONE episode = 793 number of steps = 25 reward = 0.0\n",
      "DONE episode = 794 number of steps = 27 reward = 0.0\n",
      "DONE episode = 795 number of steps = 26 reward = 0.0\n",
      "DONE episode = 796 number of steps = 25 reward = 0.0\n",
      "DONE episode = 797 number of steps = 56 reward = 1.0\n",
      "DONE episode = 798 number of steps = 26 reward = 0.0\n",
      "DONE episode = 799 number of steps = 25 reward = 0.0\n",
      "DONE episode = 800 number of steps = 27 reward = 0.0\n",
      "DONE episode = 801 number of steps = 103 reward = 2.0\n",
      "DONE episode = 802 number of steps = 26 reward = 0.0\n",
      "DONE episode = 803 number of steps = 25 reward = 0.0\n",
      "DONE episode = 804 number of steps = 25 reward = 0.0\n",
      "DONE episode = 805 number of steps = 26 reward = 0.0\n",
      "DONE episode = 806 number of steps = 27 reward = 0.0\n",
      "DONE episode = 807 number of steps = 74 reward = 1.0\n",
      "DONE episode = 808 number of steps = 25 reward = 0.0\n",
      "DONE episode = 809 number of steps = 26 reward = 0.0\n",
      "DONE episode = 810 number of steps = 26 reward = 0.0\n",
      "DONE episode = 811 number of steps = 25 reward = 0.0\n",
      "DONE episode = 812 number of steps = 27 reward = 0.0\n",
      "DONE episode = 813 number of steps = 54 reward = 1.0\n",
      "DONE episode = 814 number of steps = 26 reward = 0.0\n",
      "DONE episode = 815 number of steps = 25 reward = 0.0\n",
      "DONE episode = 816 number of steps = 25 reward = 0.0\n",
      "DONE episode = 817 number of steps = 100 reward = 2.0\n",
      "DONE episode = 818 number of steps = 151 reward = 3.0\n",
      "DONE episode = 819 number of steps = 29 reward = 0.0\n",
      "DONE episode = 820 number of steps = 27 reward = 0.0\n",
      "DONE episode = 821 number of steps = 26 reward = 0.0\n",
      "DONE episode = 822 number of steps = 26 reward = 0.0\n",
      "DONE episode = 823 number of steps = 25 reward = 0.0\n",
      "DONE episode = 824 number of steps = 53 reward = 1.0\n",
      "DONE episode = 825 number of steps = 33 reward = 0.0\n",
      "DONE episode = 826 number of steps = 27 reward = 0.0\n",
      "DONE episode = 827 number of steps = 26 reward = 0.0\n",
      "DONE episode = 828 number of steps = 55 reward = 1.0\n",
      "DONE episode = 829 number of steps = 26 reward = 0.0\n",
      "DONE episode = 830 number of steps = 28 reward = 0.0\n",
      "DONE episode = 831 number of steps = 25 reward = 0.0\n",
      "DONE episode = 832 number of steps = 27 reward = 0.0\n",
      "DONE episode = 833 number of steps = 25 reward = 0.0\n",
      "DONE episode = 834 number of steps = 25 reward = 0.0\n",
      "DONE episode = 835 number of steps = 26 reward = 0.0\n",
      "DONE episode = 836 number of steps = 28 reward = 0.0\n",
      "DONE episode = 837 number of steps = 25 reward = 0.0\n",
      "DONE episode = 838 number of steps = 25 reward = 0.0\n",
      "DONE episode = 839 number of steps = 26 reward = 0.0\n",
      "DONE episode = 840 number of steps = 74 reward = 1.0\n",
      "DONE episode = 841 number of steps = 26 reward = 0.0\n",
      "DONE episode = 842 number of steps = 27 reward = 0.0\n",
      "DONE episode = 843 number of steps = 26 reward = 0.0\n",
      "DONE episode = 844 number of steps = 26 reward = 0.0\n",
      "DONE episode = 845 number of steps = 25 reward = 0.0\n",
      "DONE episode = 846 number of steps = 27 reward = 0.0\n",
      "DONE episode = 847 number of steps = 25 reward = 0.0\n",
      "DONE episode = 848 number of steps = 27 reward = 0.0\n",
      "DONE episode = 849 number of steps = 26 reward = 0.0\n",
      "DONE episode = 850 number of steps = 29 reward = 0.0\n",
      "DONE episode = 851 number of steps = 25 reward = 0.0\n",
      "DONE episode = 852 number of steps = 25 reward = 0.0\n",
      "DONE episode = 853 number of steps = 25 reward = 0.0\n",
      "DONE episode = 854 number of steps = 55 reward = 1.0\n",
      "DONE episode = 855 number of steps = 25 reward = 0.0\n",
      "DONE episode = 856 number of steps = 25 reward = 0.0\n",
      "DONE episode = 857 number of steps = 25 reward = 0.0\n",
      "DONE episode = 858 number of steps = 25 reward = 0.0\n",
      "DONE episode = 859 number of steps = 25 reward = 0.0\n",
      "DONE episode = 860 number of steps = 25 reward = 0.0\n",
      "DONE episode = 861 number of steps = 26 reward = 0.0\n",
      "DONE episode = 862 number of steps = 26 reward = 0.0\n",
      "DONE episode = 863 number of steps = 57 reward = 1.0\n",
      "DONE episode = 864 number of steps = 27 reward = 0.0\n",
      "DONE episode = 865 number of steps = 27 reward = 0.0\n",
      "DONE episode = 866 number of steps = 26 reward = 0.0\n",
      "DONE episode = 867 number of steps = 25 reward = 0.0\n",
      "DONE episode = 868 number of steps = 25 reward = 0.0\n",
      "DONE episode = 869 number of steps = 25 reward = 0.0\n",
      "DONE episode = 870 number of steps = 53 reward = 1.0\n",
      "DONE episode = 871 number of steps = 27 reward = 0.0\n",
      "DONE episode = 872 number of steps = 26 reward = 0.0\n",
      "DONE episode = 873 number of steps = 26 reward = 0.0\n",
      "DONE episode = 874 number of steps = 25 reward = 0.0\n",
      "DONE episode = 875 number of steps = 25 reward = 0.0\n",
      "DONE episode = 876 number of steps = 104 reward = 2.0\n",
      "DONE episode = 877 number of steps = 71 reward = 1.0\n",
      "DONE episode = 878 number of steps = 27 reward = 0.0\n",
      "DONE episode = 879 number of steps = 26 reward = 0.0\n",
      "DONE episode = 880 number of steps = 26 reward = 0.0\n",
      "DONE episode = 881 number of steps = 26 reward = 0.0\n",
      "DONE episode = 882 number of steps = 26 reward = 0.0\n",
      "DONE episode = 883 number of steps = 25 reward = 0.0\n",
      "DONE episode = 884 number of steps = 25 reward = 0.0\n",
      "DONE episode = 885 number of steps = 26 reward = 0.0\n",
      "DONE episode = 886 number of steps = 26 reward = 0.0\n",
      "DONE episode = 887 number of steps = 26 reward = 0.0\n",
      "DONE episode = 888 number of steps = 53 reward = 1.0\n",
      "DONE episode = 889 number of steps = 25 reward = 0.0\n",
      "DONE episode = 890 number of steps = 26 reward = 0.0\n",
      "DONE episode = 891 number of steps = 25 reward = 0.0\n",
      "DONE episode = 892 number of steps = 25 reward = 0.0\n",
      "DONE episode = 893 number of steps = 25 reward = 0.0\n",
      "DONE episode = 894 number of steps = 29 reward = 0.0\n",
      "DONE episode = 895 number of steps = 25 reward = 0.0\n",
      "DONE episode = 896 number of steps = 26 reward = 0.0\n",
      "DONE episode = 897 number of steps = 25 reward = 0.0\n",
      "DONE episode = 898 number of steps = 53 reward = 1.0\n",
      "DONE episode = 899 number of steps = 53 reward = 1.0\n",
      "DONE episode = 900 number of steps = 25 reward = 0.0\n",
      "DONE episode = 901 number of steps = 25 reward = 0.0\n",
      "DONE episode = 902 number of steps = 26 reward = 0.0\n",
      "DONE episode = 903 number of steps = 72 reward = 1.0\n",
      "DONE episode = 904 number of steps = 26 reward = 0.0\n",
      "DONE episode = 905 number of steps = 26 reward = 0.0\n",
      "DONE episode = 906 number of steps = 26 reward = 0.0\n",
      "DONE episode = 907 number of steps = 27 reward = 0.0\n",
      "DONE episode = 908 number of steps = 25 reward = 0.0\n",
      "DONE episode = 909 number of steps = 55 reward = 1.0\n",
      "DONE episode = 910 number of steps = 25 reward = 0.0\n",
      "DONE episode = 911 number of steps = 25 reward = 0.0\n",
      "DONE episode = 912 number of steps = 26 reward = 0.0\n",
      "DONE episode = 913 number of steps = 26 reward = 0.0\n",
      "DONE episode = 914 number of steps = 27 reward = 0.0\n",
      "DONE episode = 915 number of steps = 25 reward = 0.0\n",
      "DONE episode = 916 number of steps = 25 reward = 0.0\n",
      "DONE episode = 917 number of steps = 26 reward = 0.0\n",
      "DONE episode = 918 number of steps = 25 reward = 0.0\n",
      "DONE episode = 919 number of steps = 25 reward = 0.0\n",
      "DONE episode = 920 number of steps = 25 reward = 0.0\n",
      "DONE episode = 921 number of steps = 25 reward = 0.0\n",
      "DONE episode = 922 number of steps = 25 reward = 0.0\n",
      "DONE episode = 923 number of steps = 25 reward = 0.0\n",
      "DONE episode = 924 number of steps = 26 reward = 0.0\n",
      "DONE episode = 925 number of steps = 25 reward = 0.0\n",
      "DONE episode = 926 number of steps = 25 reward = 0.0\n",
      "DONE episode = 927 number of steps = 33 reward = 0.0\n",
      "DONE episode = 928 number of steps = 102 reward = 2.0\n",
      "DONE episode = 929 number of steps = 25 reward = 0.0\n",
      "DONE episode = 930 number of steps = 27 reward = 0.0\n",
      "DONE episode = 931 number of steps = 122 reward = 2.0\n",
      "DONE episode = 932 number of steps = 25 reward = 0.0\n",
      "DONE episode = 933 number of steps = 26 reward = 0.0\n",
      "DONE episode = 934 number of steps = 27 reward = 0.0\n",
      "DONE episode = 935 number of steps = 25 reward = 0.0\n",
      "DONE episode = 936 number of steps = 26 reward = 0.0\n",
      "DONE episode = 937 number of steps = 25 reward = 0.0\n",
      "DONE episode = 938 number of steps = 25 reward = 0.0\n",
      "DONE episode = 939 number of steps = 53 reward = 1.0\n",
      "DONE episode = 940 number of steps = 53 reward = 1.0\n",
      "DONE episode = 941 number of steps = 25 reward = 0.0\n",
      "DONE episode = 942 number of steps = 26 reward = 0.0\n",
      "DONE episode = 943 number of steps = 25 reward = 0.0\n",
      "DONE episode = 944 number of steps = 25 reward = 0.0\n",
      "DONE episode = 945 number of steps = 25 reward = 0.0\n",
      "DONE episode = 946 number of steps = 25 reward = 0.0\n",
      "DONE episode = 947 number of steps = 25 reward = 0.0\n",
      "DONE episode = 948 number of steps = 26 reward = 0.0\n",
      "DONE episode = 949 number of steps = 25 reward = 0.0\n",
      "DONE episode = 950 number of steps = 27 reward = 0.0\n",
      "DONE episode = 951 number of steps = 25 reward = 0.0\n",
      "DONE episode = 952 number of steps = 25 reward = 0.0\n",
      "DONE episode = 953 number of steps = 71 reward = 1.0\n",
      "DONE episode = 954 number of steps = 28 reward = 0.0\n",
      "DONE episode = 955 number of steps = 25 reward = 0.0\n",
      "DONE episode = 956 number of steps = 53 reward = 1.0\n",
      "DONE episode = 957 number of steps = 26 reward = 0.0\n",
      "DONE episode = 958 number of steps = 25 reward = 0.0\n",
      "DONE episode = 959 number of steps = 54 reward = 1.0\n",
      "DONE episode = 960 number of steps = 76 reward = 1.0\n",
      "DONE episode = 961 number of steps = 26 reward = 0.0\n",
      "DONE episode = 962 number of steps = 122 reward = 2.0\n",
      "DONE episode = 963 number of steps = 25 reward = 0.0\n",
      "DONE episode = 964 number of steps = 53 reward = 1.0\n",
      "DONE episode = 965 number of steps = 26 reward = 0.0\n",
      "DONE episode = 966 number of steps = 32 reward = 0.0\n",
      "DONE episode = 967 number of steps = 84 reward = 2.0\n",
      "DONE episode = 968 number of steps = 25 reward = 0.0\n",
      "DONE episode = 969 number of steps = 26 reward = 0.0\n",
      "DONE episode = 970 number of steps = 27 reward = 0.0\n",
      "DONE episode = 971 number of steps = 25 reward = 0.0\n",
      "DONE episode = 972 number of steps = 71 reward = 1.0\n",
      "DONE episode = 973 number of steps = 25 reward = 0.0\n",
      "DONE episode = 974 number of steps = 25 reward = 0.0\n",
      "DONE episode = 975 number of steps = 28 reward = 0.0\n",
      "DONE episode = 976 number of steps = 27 reward = 0.0\n",
      "DONE episode = 977 number of steps = 27 reward = 0.0\n",
      "DONE episode = 978 number of steps = 28 reward = 0.0\n",
      "DONE episode = 979 number of steps = 26 reward = 0.0\n",
      "DONE episode = 980 number of steps = 26 reward = 0.0\n",
      "DONE episode = 981 number of steps = 25 reward = 0.0\n",
      "DONE episode = 982 number of steps = 25 reward = 0.0\n",
      "DONE episode = 983 number of steps = 53 reward = 1.0\n",
      "DONE episode = 984 number of steps = 53 reward = 1.0\n",
      "DONE episode = 985 number of steps = 25 reward = 0.0\n",
      "DONE episode = 986 number of steps = 27 reward = 0.0\n",
      "DONE episode = 987 number of steps = 27 reward = 0.0\n",
      "DONE episode = 988 number of steps = 27 reward = 0.0\n",
      "DONE episode = 989 number of steps = 25 reward = 0.0\n",
      "DONE episode = 990 number of steps = 25 reward = 0.0\n",
      "DONE episode = 991 number of steps = 25 reward = 0.0\n",
      "DONE episode = 992 number of steps = 25 reward = 0.0\n",
      "DONE episode = 993 number of steps = 27 reward = 0.0\n",
      "DONE episode = 994 number of steps = 84 reward = 2.0\n",
      "DONE episode = 995 number of steps = 27 reward = 0.0\n",
      "DONE episode = 996 number of steps = 56 reward = 1.0\n",
      "DONE episode = 997 number of steps = 26 reward = 0.0\n",
      "DONE episode = 998 number of steps = 25 reward = 0.0\n",
      "DONE episode = 999 number of steps = 33 reward = 0.0\n",
      "DONE episode = 1000 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1001 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1002 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1003 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1004 number of steps = 57 reward = 1.0\n",
      "DONE episode = 1005 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1006 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1007 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1008 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1009 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1010 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1011 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1012 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1013 number of steps = 29 reward = 0.0\n",
      "DONE episode = 1014 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1015 number of steps = 29 reward = 0.0\n",
      "DONE episode = 1016 number of steps = 156 reward = 3.0\n",
      "DONE episode = 1017 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1018 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1019 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1020 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1021 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1022 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1023 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1024 number of steps = 31 reward = 0.0\n",
      "DONE episode = 1025 number of steps = 30 reward = 0.0\n",
      "DONE episode = 1026 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1027 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1028 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1029 number of steps = 30 reward = 0.0\n",
      "DONE episode = 1030 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1031 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1032 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1033 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1034 number of steps = 30 reward = 0.0\n",
      "DONE episode = 1035 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1036 number of steps = 30 reward = 0.0\n",
      "DONE episode = 1037 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1038 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1039 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1040 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1041 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1042 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1043 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1044 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1045 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1046 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1047 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1048 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1049 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1050 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1051 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1052 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1053 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1054 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1055 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1056 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1057 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1058 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1059 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1060 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1061 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1062 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1063 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1064 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1065 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1066 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1067 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1068 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1069 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1070 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1071 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1072 number of steps = 87 reward = 2.0\n",
      "DONE episode = 1073 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1074 number of steps = 57 reward = 1.0\n",
      "DONE episode = 1075 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1076 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1077 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1078 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1079 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1080 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1081 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1082 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1083 number of steps = 30 reward = 0.0\n",
      "DONE episode = 1084 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1085 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1086 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1087 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1088 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1089 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1090 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1091 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1092 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1093 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1094 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1095 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1096 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1097 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1098 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1099 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1100 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1101 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1102 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1103 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1104 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1105 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1106 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1107 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1108 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1109 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1110 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1111 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1112 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1113 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1114 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1115 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1116 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1117 number of steps = 119 reward = 2.0\n",
      "DONE episode = 1118 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1119 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1120 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1121 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1122 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1123 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1124 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1125 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1126 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1127 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1128 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1129 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1130 number of steps = 105 reward = 2.0\n",
      "DONE episode = 1131 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1132 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1133 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1134 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1135 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1136 number of steps = 127 reward = 2.0\n",
      "DONE episode = 1137 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1138 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1139 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1140 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1141 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1142 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1143 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1144 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1145 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1146 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1147 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1148 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1149 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1150 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1151 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1152 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1153 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1154 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1155 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1156 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1157 number of steps = 29 reward = 0.0\n",
      "DONE episode = 1158 number of steps = 121 reward = 2.0\n",
      "DONE episode = 1159 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1160 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1161 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1162 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1163 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1164 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1165 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1166 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1167 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1168 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1169 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1170 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1171 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1172 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1173 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1174 number of steps = 100 reward = 2.0\n",
      "DONE episode = 1175 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1176 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1177 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1178 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1179 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1180 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1181 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1182 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1183 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1184 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1185 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1186 number of steps = 34 reward = 0.0\n",
      "DONE episode = 1187 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1188 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1189 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1190 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1191 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1192 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1193 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1194 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1195 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1196 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1197 number of steps = 121 reward = 2.0\n",
      "DONE episode = 1198 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1199 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1200 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1201 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1202 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1203 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1204 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1205 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1206 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1207 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1208 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1209 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1210 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1211 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1212 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1213 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1214 number of steps = 56 reward = 1.0\n",
      "DONE episode = 1215 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1216 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1217 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1218 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1219 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1220 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1221 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1222 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1223 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1224 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1225 number of steps = 103 reward = 2.0\n",
      "DONE episode = 1226 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1227 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1228 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1229 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1230 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1231 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1232 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1233 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1234 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1235 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1236 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1237 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1238 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1239 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1240 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1241 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1242 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1243 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1244 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1245 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1246 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1247 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1248 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1249 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1250 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1251 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1252 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1253 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1254 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1255 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1256 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1257 number of steps = 121 reward = 2.0\n",
      "DONE episode = 1258 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1259 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1260 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1261 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1262 number of steps = 31 reward = 0.0\n",
      "DONE episode = 1263 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1264 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1265 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1266 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1267 number of steps = 56 reward = 1.0\n",
      "DONE episode = 1268 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1269 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1270 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1271 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1272 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1273 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1274 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1275 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1276 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1277 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1278 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1279 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1280 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1281 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1282 number of steps = 138 reward = 3.0\n",
      "DONE episode = 1283 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1284 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1285 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1286 number of steps = 89 reward = 2.0\n",
      "DONE episode = 1287 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1288 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1289 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1290 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1291 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1292 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1293 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1294 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1295 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1296 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1297 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1298 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1299 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1300 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1301 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1302 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1303 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1304 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1305 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1306 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1307 number of steps = 29 reward = 0.0\n",
      "DONE episode = 1308 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1309 number of steps = 76 reward = 1.0\n",
      "DONE episode = 1310 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1311 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1312 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1313 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1314 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1315 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1316 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1317 number of steps = 118 reward = 2.0\n",
      "DONE episode = 1318 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1319 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1320 number of steps = 56 reward = 1.0\n",
      "DONE episode = 1321 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1322 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1323 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1324 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1325 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1326 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1327 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1328 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1329 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1330 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1331 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1332 number of steps = 100 reward = 2.0\n",
      "DONE episode = 1333 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1334 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1335 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1336 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1337 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1338 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1339 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1340 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1341 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1342 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1343 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1344 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1345 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1346 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1347 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1348 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1349 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1350 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1351 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1352 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1353 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1354 number of steps = 172 reward = 4.0\n",
      "DONE episode = 1355 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1356 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1357 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1358 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1359 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1360 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1361 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1362 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1363 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1364 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1365 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1366 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1367 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1368 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1369 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1370 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1371 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1372 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1373 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1374 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1375 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1376 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1377 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1378 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1379 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1380 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1381 number of steps = 100 reward = 2.0\n",
      "DONE episode = 1382 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1383 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1384 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1385 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1386 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1387 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1388 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1389 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1390 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1391 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1392 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1393 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1394 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1395 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1396 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1397 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1398 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1399 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1400 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1401 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1402 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1403 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1404 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1405 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1406 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1407 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1408 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1409 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1410 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1411 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1412 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1413 number of steps = 149 reward = 3.0\n",
      "DONE episode = 1414 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1415 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1416 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1417 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1418 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1419 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1420 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1421 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1422 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1423 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1424 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1425 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1426 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1427 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1428 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1429 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1430 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1431 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1432 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1433 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1434 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1435 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1436 number of steps = 88 reward = 2.0\n",
      "DONE episode = 1437 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1438 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1439 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1440 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1441 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1442 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1443 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1444 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1445 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1446 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1447 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1448 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1449 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1450 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1451 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1452 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1453 number of steps = 107 reward = 2.0\n",
      "DONE episode = 1454 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1455 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1456 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1457 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1458 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1459 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1460 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1461 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1462 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1463 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1464 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1465 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1466 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1467 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1468 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1469 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1470 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1471 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1472 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1473 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1474 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1475 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1476 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1477 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1478 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1479 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1480 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1481 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1482 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1483 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1484 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1485 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1486 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1487 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1488 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1489 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1490 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1491 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1492 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1493 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1494 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1495 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1496 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1497 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1498 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1499 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1500 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1501 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1502 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1503 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1504 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1505 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1506 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1507 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1508 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1509 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1510 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1511 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1512 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1513 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1514 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1515 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1516 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1517 number of steps = 119 reward = 2.0\n",
      "DONE episode = 1518 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1519 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1520 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1521 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1522 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1523 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1524 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1525 number of steps = 29 reward = 0.0\n",
      "DONE episode = 1526 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1527 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1528 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1529 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1530 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1531 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1532 number of steps = 85 reward = 2.0\n",
      "DONE episode = 1533 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1534 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1535 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1536 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1537 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1538 number of steps = 121 reward = 2.0\n",
      "DONE episode = 1539 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1540 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1541 number of steps = 122 reward = 2.0\n",
      "DONE episode = 1542 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1543 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1544 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1545 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1546 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1547 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1548 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1549 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1550 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1551 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1552 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1553 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1554 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1555 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1556 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1557 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1558 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1559 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1560 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1561 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1562 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1563 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1564 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1565 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1566 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1567 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1568 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1569 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1570 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1571 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1572 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1573 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1574 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1575 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1576 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1577 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1578 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1579 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1580 number of steps = 56 reward = 1.0\n",
      "DONE episode = 1581 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1582 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1583 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1584 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1585 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1586 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1587 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1588 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1589 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1590 number of steps = 31 reward = 0.0\n",
      "DONE episode = 1591 number of steps = 37 reward = 0.0\n",
      "DONE episode = 1592 number of steps = 31 reward = 0.0\n",
      "DONE episode = 1593 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1594 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1595 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1596 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1597 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1598 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1599 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1600 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1601 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1602 number of steps = 33 reward = 0.0\n",
      "DONE episode = 1603 number of steps = 29 reward = 0.0\n",
      "DONE episode = 1604 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1605 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1606 number of steps = 29 reward = 0.0\n",
      "DONE episode = 1607 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1608 number of steps = 101 reward = 2.0\n",
      "DONE episode = 1609 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1610 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1611 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1612 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1613 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1614 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1615 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1616 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1617 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1618 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1619 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1620 number of steps = 102 reward = 2.0\n",
      "DONE episode = 1621 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1622 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1623 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1624 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1625 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1626 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1627 number of steps = 102 reward = 2.0\n",
      "DONE episode = 1628 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1629 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1630 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1631 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1632 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1633 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1634 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1635 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1636 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1637 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1638 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1639 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1640 number of steps = 42 reward = 0.0\n",
      "DONE episode = 1641 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1642 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1643 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1644 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1645 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1646 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1647 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1648 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1649 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1650 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1651 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1652 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1653 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1654 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1655 number of steps = 122 reward = 2.0\n",
      "DONE episode = 1656 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1657 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1658 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1659 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1660 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1661 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1662 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1663 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1664 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1665 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1666 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1667 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1668 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1669 number of steps = 147 reward = 3.0\n",
      "DONE episode = 1670 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1671 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1672 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1673 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1674 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1675 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1676 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1677 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1678 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1679 number of steps = 30 reward = 0.0\n",
      "DONE episode = 1680 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1681 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1682 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1683 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1684 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1685 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1686 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1687 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1688 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1689 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1690 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1691 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1692 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1693 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1694 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1695 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1696 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1697 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1698 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1699 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1700 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1701 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1702 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1703 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1704 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1705 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1706 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1707 number of steps = 102 reward = 2.0\n",
      "DONE episode = 1708 number of steps = 103 reward = 2.0\n",
      "DONE episode = 1709 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1710 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1711 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1712 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1713 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1714 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1715 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1716 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1717 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1718 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1719 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1720 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1721 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1722 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1723 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1724 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1725 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1726 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1727 number of steps = 75 reward = 1.0\n",
      "DONE episode = 1728 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1729 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1730 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1731 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1732 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1733 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1734 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1735 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1736 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1737 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1738 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1739 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1740 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1741 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1742 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1743 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1744 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1745 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1746 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1747 number of steps = 101 reward = 2.0\n",
      "DONE episode = 1748 number of steps = 100 reward = 2.0\n",
      "DONE episode = 1749 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1750 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1751 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1752 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1753 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1754 number of steps = 76 reward = 1.0\n",
      "DONE episode = 1755 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1756 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1757 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1758 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1759 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1760 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1761 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1762 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1763 number of steps = 56 reward = 1.0\n",
      "DONE episode = 1764 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1765 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1766 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1767 number of steps = 31 reward = 0.0\n",
      "DONE episode = 1768 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1769 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1770 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1771 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1772 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1773 number of steps = 102 reward = 2.0\n",
      "DONE episode = 1774 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1775 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1776 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1777 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1778 number of steps = 122 reward = 2.0\n",
      "DONE episode = 1779 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1780 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1781 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1782 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1783 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1784 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1785 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1786 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1787 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1788 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1789 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1790 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1791 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1792 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1793 number of steps = 87 reward = 2.0\n",
      "DONE episode = 1794 number of steps = 75 reward = 1.0\n",
      "DONE episode = 1795 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1796 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1797 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1798 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1799 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1800 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1801 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1802 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1803 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1804 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1805 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1806 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1807 number of steps = 119 reward = 2.0\n",
      "DONE episode = 1808 number of steps = 172 reward = 3.0\n",
      "DONE episode = 1809 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1810 number of steps = 100 reward = 2.0\n",
      "DONE episode = 1811 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1812 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1813 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1814 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1815 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1816 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1817 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1818 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1819 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1820 number of steps = 133 reward = 3.0\n",
      "DONE episode = 1821 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1822 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1823 number of steps = 56 reward = 1.0\n",
      "DONE episode = 1824 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1825 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1826 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1827 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1828 number of steps = 151 reward = 3.0\n",
      "DONE episode = 1829 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1830 number of steps = 131 reward = 3.0\n",
      "DONE episode = 1831 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1832 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1833 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1834 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1835 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1836 number of steps = 75 reward = 1.0\n",
      "DONE episode = 1837 number of steps = 32 reward = 0.0\n",
      "DONE episode = 1838 number of steps = 28 reward = 0.0\n",
      "DONE episode = 1839 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1840 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1841 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1842 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1843 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1844 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1845 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1846 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1847 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1848 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1849 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1850 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1851 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1852 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1853 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1854 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1855 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1856 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1857 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1858 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1859 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1860 number of steps = 103 reward = 2.0\n",
      "DONE episode = 1861 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1862 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1863 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1864 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1865 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1866 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1867 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1868 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1869 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1870 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1871 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1872 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1873 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1874 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1875 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1876 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1877 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1878 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1879 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1880 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1881 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1882 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1883 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1884 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1885 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1886 number of steps = 54 reward = 1.0\n",
      "DONE episode = 1887 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1888 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1889 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1890 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1891 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1892 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1893 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1894 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1895 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1896 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1897 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1898 number of steps = 104 reward = 2.0\n",
      "DONE episode = 1899 number of steps = 123 reward = 2.0\n",
      "DONE episode = 1900 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1901 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1902 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1903 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1904 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1905 number of steps = 74 reward = 1.0\n",
      "DONE episode = 1906 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1907 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1908 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1909 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1910 number of steps = 55 reward = 1.0\n",
      "DONE episode = 1911 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1912 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1913 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1914 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1915 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1916 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1917 number of steps = 88 reward = 2.0\n",
      "DONE episode = 1918 number of steps = 73 reward = 1.0\n",
      "DONE episode = 1919 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1920 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1921 number of steps = 105 reward = 2.0\n",
      "DONE episode = 1922 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1923 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1924 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1925 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1926 number of steps = 86 reward = 2.0\n",
      "DONE episode = 1927 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1928 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1929 number of steps = 88 reward = 2.0\n",
      "DONE episode = 1930 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1931 number of steps = 27 reward = 0.0\n",
      "DONE episode = 1932 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1933 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1934 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1935 number of steps = 118 reward = 2.0\n",
      "DONE episode = 1936 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1937 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1938 number of steps = 84 reward = 2.0\n",
      "DONE episode = 1939 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1940 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1941 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1942 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1943 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1944 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1945 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1946 number of steps = 72 reward = 1.0\n",
      "DONE episode = 1947 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1948 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1949 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1950 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1951 number of steps = 86 reward = 2.0\n",
      "DONE episode = 1952 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1953 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1954 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1955 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1956 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1957 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1958 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1959 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1960 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1961 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1962 number of steps = 89 reward = 2.0\n",
      "DONE episode = 1963 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1964 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1965 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1966 number of steps = 151 reward = 3.0\n",
      "DONE episode = 1967 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1968 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1969 number of steps = 175 reward = 3.0\n",
      "DONE episode = 1970 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1971 number of steps = 101 reward = 2.0\n",
      "DONE episode = 1972 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1973 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1974 number of steps = 121 reward = 2.0\n",
      "DONE episode = 1975 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1976 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1977 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1978 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1979 number of steps = 86 reward = 2.0\n",
      "DONE episode = 1980 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1981 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1982 number of steps = 53 reward = 1.0\n",
      "DONE episode = 1983 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1984 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1985 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1986 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1987 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1988 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1989 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1990 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1991 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1992 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1993 number of steps = 26 reward = 0.0\n",
      "DONE episode = 1994 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1995 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1996 number of steps = 71 reward = 1.0\n",
      "DONE episode = 1997 number of steps = 25 reward = 0.0\n",
      "DONE episode = 1998 number of steps = 154 reward = 3.0\n",
      "DONE episode = 1999 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2000 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2001 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2002 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2003 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2004 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2005 number of steps = 26 reward = 0.0\n",
      "DONE episode = 2006 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2007 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2008 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2009 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2010 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2011 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2012 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2013 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2014 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2015 number of steps = 131 reward = 3.0\n",
      "DONE episode = 2016 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2017 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2018 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2019 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2020 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2021 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2022 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2023 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2024 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2025 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2026 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2027 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2028 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2029 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2030 number of steps = 56 reward = 1.0\n",
      "DONE episode = 2031 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2032 number of steps = 83 reward = 1.0\n",
      "DONE episode = 2033 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2034 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2035 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2036 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2037 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2038 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2039 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2040 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2041 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2042 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2043 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2044 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2045 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2046 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2047 number of steps = 26 reward = 0.0\n",
      "DONE episode = 2048 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2049 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2050 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2051 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2052 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2053 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2054 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2055 number of steps = 26 reward = 0.0\n",
      "DONE episode = 2056 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2057 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2058 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2059 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2060 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2061 number of steps = 26 reward = 0.0\n",
      "DONE episode = 2062 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2063 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2064 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2065 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2066 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2067 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2068 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2069 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2070 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2071 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2072 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2073 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2074 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2075 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2076 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2077 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2078 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2079 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2080 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2081 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2082 number of steps = 104 reward = 2.0\n",
      "DONE episode = 2083 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2084 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2085 number of steps = 73 reward = 1.0\n",
      "DONE episode = 2086 number of steps = 123 reward = 2.0\n",
      "DONE episode = 2087 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2088 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2089 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2090 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2091 number of steps = 86 reward = 2.0\n",
      "DONE episode = 2092 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2093 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2094 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2095 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2096 number of steps = 104 reward = 2.0\n",
      "DONE episode = 2097 number of steps = 73 reward = 1.0\n",
      "DONE episode = 2098 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2099 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2100 number of steps = 149 reward = 3.0\n",
      "DONE episode = 2101 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2102 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2103 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2104 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2105 number of steps = 26 reward = 0.0\n",
      "DONE episode = 2106 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2107 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2108 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2109 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2110 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2111 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2112 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2113 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2114 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2115 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2116 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2117 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2118 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2119 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2120 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2121 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2122 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2123 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2124 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2125 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2126 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2127 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2128 number of steps = 140 reward = 4.0\n",
      "DONE episode = 2129 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2130 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2131 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2132 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2133 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2134 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2135 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2136 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2137 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2138 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2139 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2140 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2141 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2142 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2143 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2144 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2145 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2146 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2147 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2148 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2149 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2150 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2151 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2152 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2153 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2154 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2155 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2156 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2157 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2158 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2159 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2160 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2161 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2162 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2163 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2164 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2165 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2166 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2167 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2168 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2169 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2170 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2171 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2172 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2173 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2174 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2175 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2176 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2177 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2178 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2179 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2180 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2181 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2182 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2183 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2184 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2185 number of steps = 54 reward = 1.0\n",
      "DONE episode = 2186 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2187 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2188 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2189 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2190 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2191 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2192 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2193 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2194 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2195 number of steps = 150 reward = 3.0\n",
      "DONE episode = 2196 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2197 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2198 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2199 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2200 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2201 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2202 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2203 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2204 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2205 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2206 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2207 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2208 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2209 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2210 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2211 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2212 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2213 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2214 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2215 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2216 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2217 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2218 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2219 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2220 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2221 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2222 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2223 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2224 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2225 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2226 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2227 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2228 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2229 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2230 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2231 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2232 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2233 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2234 number of steps = 173 reward = 3.0\n",
      "DONE episode = 2235 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2236 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2237 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2238 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2239 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2240 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2241 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2242 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2243 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2244 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2245 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2246 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2247 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2248 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2249 number of steps = 123 reward = 2.0\n",
      "DONE episode = 2250 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2251 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2252 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2253 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2254 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2255 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2256 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2257 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2258 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2259 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2260 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2261 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2262 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2263 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2264 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2265 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2266 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2267 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2268 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2269 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2270 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2271 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2272 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2273 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2274 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2275 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2276 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2277 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2278 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2279 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2280 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2281 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2282 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2283 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2284 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2285 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2286 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2287 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2288 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2289 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2290 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2291 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2292 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2293 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2294 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2295 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2296 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2297 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2298 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2299 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2300 number of steps = 173 reward = 3.0\n",
      "DONE episode = 2301 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2302 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2303 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2304 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2305 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2306 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2307 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2308 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2309 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2310 number of steps = 173 reward = 4.0\n",
      "DONE episode = 2311 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2312 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2313 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2314 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2315 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2316 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2317 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2318 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2319 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2320 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2321 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2322 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2323 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2324 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2325 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2326 number of steps = 168 reward = 3.0\n",
      "DONE episode = 2327 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2328 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2329 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2330 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2331 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2332 number of steps = 120 reward = 2.0\n",
      "DONE episode = 2333 number of steps = 26 reward = 0.0\n",
      "DONE episode = 2334 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2335 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2336 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2337 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2338 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2339 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2340 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2341 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2342 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2343 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2344 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2345 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2346 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2347 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2348 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2349 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2350 number of steps = 143 reward = 4.0\n",
      "DONE episode = 2351 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2352 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2353 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2354 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2355 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2356 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2357 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2358 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2359 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2360 number of steps = 120 reward = 2.0\n",
      "DONE episode = 2361 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2362 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2363 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2364 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2365 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2366 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2367 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2368 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2369 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2370 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2371 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2372 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2373 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2374 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2375 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2376 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2377 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2378 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2379 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2380 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2381 number of steps = 86 reward = 2.0\n",
      "DONE episode = 2382 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2383 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2384 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2385 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2386 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2387 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2388 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2389 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2390 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2391 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2392 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2393 number of steps = 26 reward = 0.0\n",
      "DONE episode = 2394 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2395 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2396 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2397 number of steps = 75 reward = 1.0\n",
      "DONE episode = 2398 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2399 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2400 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2401 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2402 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2403 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2404 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2405 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2406 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2407 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2408 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2409 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2410 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2411 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2412 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2413 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2414 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2415 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2416 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2417 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2418 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2419 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2420 number of steps = 139 reward = 2.0\n",
      "DONE episode = 2421 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2422 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2423 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2424 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2425 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2426 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2427 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2428 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2429 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2430 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2431 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2432 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2433 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2434 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2435 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2436 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2437 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2438 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2439 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2440 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2441 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2442 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2443 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2444 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2445 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2446 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2447 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2448 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2449 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2450 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2451 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2452 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2453 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2454 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2455 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2456 number of steps = 138 reward = 3.0\n",
      "DONE episode = 2457 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2458 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2459 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2460 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2461 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2462 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2463 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2464 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2465 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2466 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2467 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2468 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2469 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2470 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2471 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2472 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2473 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2474 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2475 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2476 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2477 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2478 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2479 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2480 number of steps = 104 reward = 2.0\n",
      "DONE episode = 2481 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2482 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2483 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2484 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2485 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2486 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2487 number of steps = 54 reward = 1.0\n",
      "DONE episode = 2488 number of steps = 138 reward = 3.0\n",
      "DONE episode = 2489 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2490 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2491 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2492 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2493 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2494 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2495 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2496 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2497 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2498 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2499 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2500 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2501 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2502 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2503 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2504 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2505 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2506 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2507 number of steps = 124 reward = 2.0\n",
      "DONE episode = 2508 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2509 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2510 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2511 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2512 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2513 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2514 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2515 number of steps = 123 reward = 2.0\n",
      "DONE episode = 2516 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2517 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2518 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2519 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2520 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2521 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2522 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2523 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2524 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2525 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2526 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2527 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2528 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2529 number of steps = 123 reward = 2.0\n",
      "DONE episode = 2530 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2531 number of steps = 141 reward = 4.0\n",
      "DONE episode = 2532 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2533 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2534 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2535 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2536 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2537 number of steps = 123 reward = 2.0\n",
      "DONE episode = 2538 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2539 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2540 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2541 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2542 number of steps = 191 reward = 4.0\n",
      "DONE episode = 2543 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2544 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2545 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2546 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2547 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2548 number of steps = 124 reward = 2.0\n",
      "DONE episode = 2549 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2550 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2551 number of steps = 121 reward = 3.0\n",
      "DONE episode = 2552 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2553 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2554 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2555 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2556 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2557 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2558 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2559 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2560 number of steps = 137 reward = 3.0\n",
      "DONE episode = 2561 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2562 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2563 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2564 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2565 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2566 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2567 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2568 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2569 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2570 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2571 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2572 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2573 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2574 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2575 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2576 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2577 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2578 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2579 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2580 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2581 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2582 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2583 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2584 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2585 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2586 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2587 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2588 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2589 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2590 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2591 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2592 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2593 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2594 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2595 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2596 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2597 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2598 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2599 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2600 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2601 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2602 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2603 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2604 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2605 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2606 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2607 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2608 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2609 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2610 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2611 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2612 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2613 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2614 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2615 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2616 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2617 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2618 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2619 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2620 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2621 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2622 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2623 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2624 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2625 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2626 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2627 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2628 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2629 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2630 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2631 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2632 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2633 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2634 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2635 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2636 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2637 number of steps = 121 reward = 3.0\n",
      "DONE episode = 2638 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2639 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2640 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2641 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2642 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2643 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2644 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2645 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2646 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2647 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2648 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2649 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2650 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2651 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2652 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2653 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2654 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2655 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2656 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2657 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2658 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2659 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2660 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2661 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2662 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2663 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2664 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2665 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2666 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2667 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2668 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2669 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2670 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2671 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2672 number of steps = 119 reward = 2.0\n",
      "DONE episode = 2673 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2674 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2675 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2676 number of steps = 104 reward = 2.0\n",
      "DONE episode = 2677 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2678 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2679 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2680 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2681 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2682 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2683 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2684 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2685 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2686 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2687 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2688 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2689 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2690 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2691 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2692 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2693 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2694 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2695 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2696 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2697 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2698 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2699 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2700 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2701 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2702 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2703 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2704 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2705 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2706 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2707 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2708 number of steps = 104 reward = 2.0\n",
      "DONE episode = 2709 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2710 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2711 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2712 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2713 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2714 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2715 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2716 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2717 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2718 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2719 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2720 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2721 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2722 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2723 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2724 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2725 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2726 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2727 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2728 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2729 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2730 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2731 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2732 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2733 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2734 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2735 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2736 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2737 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2738 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2739 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2740 number of steps = 103 reward = 2.0\n",
      "DONE episode = 2741 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2742 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2743 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2744 number of steps = 119 reward = 3.0\n",
      "DONE episode = 2745 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2746 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2747 number of steps = 101 reward = 2.0\n",
      "DONE episode = 2748 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2749 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2750 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2751 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2752 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2753 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2754 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2755 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2756 number of steps = 103 reward = 2.0\n",
      "DONE episode = 2757 number of steps = 123 reward = 2.0\n",
      "DONE episode = 2758 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2759 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2760 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2761 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2762 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2763 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2764 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2765 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2766 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2767 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2768 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2769 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2770 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2771 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2772 number of steps = 73 reward = 1.0\n",
      "DONE episode = 2773 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2774 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2775 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2776 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2777 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2778 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2779 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2780 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2781 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2782 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2783 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2784 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2785 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2786 number of steps = 55 reward = 1.0\n",
      "DONE episode = 2787 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2788 number of steps = 103 reward = 2.0\n",
      "DONE episode = 2789 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2790 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2791 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2792 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2793 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2794 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2795 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2796 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2797 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2798 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2799 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2800 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2801 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2802 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2803 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2804 number of steps = 120 reward = 2.0\n",
      "DONE episode = 2805 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2806 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2807 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2808 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2809 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2810 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2811 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2812 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2813 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2814 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2815 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2816 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2817 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2818 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2819 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2820 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2821 number of steps = 104 reward = 2.0\n",
      "DONE episode = 2822 number of steps = 104 reward = 2.0\n",
      "DONE episode = 2823 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2824 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2825 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2826 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2827 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2828 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2829 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2830 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2831 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2832 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2833 number of steps = 152 reward = 3.0\n",
      "DONE episode = 2834 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2835 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2836 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2837 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2838 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2839 number of steps = 123 reward = 2.0\n",
      "DONE episode = 2840 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2841 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2842 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2843 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2844 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2845 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2846 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2847 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2848 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2849 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2850 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2851 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2852 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2853 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2854 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2855 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2856 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2857 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2858 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2859 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2860 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2861 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2862 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2863 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2864 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2865 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2866 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2867 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2868 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2869 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2870 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2871 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2872 number of steps = 125 reward = 2.0\n",
      "DONE episode = 2873 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2874 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2875 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2876 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2877 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2878 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2879 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2880 number of steps = 168 reward = 4.0\n",
      "DONE episode = 2881 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2882 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2883 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2884 number of steps = 168 reward = 4.0\n",
      "DONE episode = 2885 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2886 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2887 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2888 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2889 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2890 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2891 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2892 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2893 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2894 number of steps = 75 reward = 1.0\n",
      "DONE episode = 2895 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2896 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2897 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2898 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2899 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2900 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2901 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2902 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2903 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2904 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2905 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2906 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2907 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2908 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2909 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2910 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2911 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2912 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2913 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2914 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2915 number of steps = 173 reward = 4.0\n",
      "DONE episode = 2916 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2917 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2918 number of steps = 122 reward = 2.0\n",
      "DONE episode = 2919 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2920 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2921 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2922 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2923 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2924 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2925 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2926 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2927 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2928 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2929 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2930 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2931 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2932 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2933 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2934 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2935 number of steps = 88 reward = 2.0\n",
      "DONE episode = 2936 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2937 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2938 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2939 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2940 number of steps = 121 reward = 2.0\n",
      "DONE episode = 2941 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2942 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2943 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2944 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2945 number of steps = 125 reward = 2.0\n",
      "DONE episode = 2946 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2947 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2948 number of steps = 124 reward = 2.0\n",
      "DONE episode = 2949 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2950 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2951 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2952 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2953 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2954 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2955 number of steps = 118 reward = 2.0\n",
      "DONE episode = 2956 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2957 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2958 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2959 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2960 number of steps = 72 reward = 1.0\n",
      "DONE episode = 2961 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2962 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2963 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2964 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2965 number of steps = 118 reward = 2.0\n",
      "DONE episode = 2966 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2967 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2968 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2969 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2970 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2971 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2972 number of steps = 100 reward = 2.0\n",
      "DONE episode = 2973 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2974 number of steps = 102 reward = 2.0\n",
      "DONE episode = 2975 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2976 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2977 number of steps = 53 reward = 1.0\n",
      "DONE episode = 2978 number of steps = 121 reward = 3.0\n",
      "DONE episode = 2979 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2980 number of steps = 25 reward = 0.0\n",
      "DONE episode = 2981 number of steps = 74 reward = 1.0\n",
      "DONE episode = 2982 number of steps = 71 reward = 1.0\n",
      "DONE episode = 2983 number of steps = 213 reward = 5.0\n",
      "DONE episode = 2984 number of steps = 102 reward = 2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if let_training:\n",
    "    training()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c509d-475a-46f4-ad95-b556fd1e7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "if let_play:\n",
    "    tot_rewards = 0\n",
    "    tot_steps = 0\n",
    "    max_reward = 0\n",
    "    rewards = []\n",
    "    steps_arr = []\n",
    "    \n",
    "    if rec_video:\n",
    "        \n",
    "        path_v = \"{}_video\".format(game_name)\n",
    "        index_v = 0\n",
    "\n",
    "        directory_n = \"{}\".format(path_v)\n",
    "        directory = Path(\"./{}\".format(directory_n))\n",
    "        while directory.exists():\n",
    "            index_v += 1\n",
    "            directory_n = \"{}-{}\".format(path_v, index_v)\n",
    "            directory = Path(\"./{}\".format(directory_n))\n",
    "        \n",
    "        env = RecordVideo(env, directory)\n",
    "    for i in range(0, games_to_play):\n",
    "        reward, steps = play()\n",
    "        tot_rewards += reward\n",
    "        tot_steps += steps\n",
    "        rewards.append(reward)\n",
    "        steps_arr.append(steps)\n",
    "        \n",
    "        if max_reward < reward:\n",
    "            max_reward = reward\n",
    "    \n",
    "    ext = \"png\"\n",
    "    name_plot_steps = \"{} Playing Episodes Steps.{}\".format(game_name, ext)\n",
    "    name_plot_rewards = \"{} Playing Episodes Rewards.{}\".format(game_name, ext)\n",
    "    file_plot_1 = Path(name_plot_steps)\n",
    "    i = 1\n",
    "    while file_plot_1.exists():\n",
    "        i += 1\n",
    "        name_plot_steps = \"{} Playing Episodes Steps_{}.{}\".format(game_name, i, ext)\n",
    "        name_plot_rewards = \"{} Playing Episodes Rewards_{}.{}\".format(game_name, i, ext)\n",
    "        file_plot_1 = Path(name_plot_steps)\n",
    "\n",
    "    plot_result(\"Game\", \"Steps\", range(1, games_to_play + 1), steps_arr, name_plot_steps)\n",
    "    plot_result(\"Game\", \"Rewards\", range(1, games_to_play + 1), rewards, name_plot_rewards)\n",
    "    \n",
    "    print(\"Max REWARD {}\".format(max_reward))\n",
    "    print(\"Average REWARD {}\".format(tot_rewards/games_to_play))\n",
    "    print(\"Average STEPS {}\".format(tot_steps/games_to_play))\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1591b57d-fb25-42cc-a552-6602dfd4d161",
   "metadata": {},
   "source": [
    "# Video demostration of the agent's ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391deda-eabc-427a-9c34-8ed1532f1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "video = \"./asterix_video/rl-video-episode-0.mp4\".format(game_name) \n",
    "Video(video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77KRHlFFhhNG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665074736231,
     "user": {
      "displayName": "stefano romeo",
      "userId": "04091680816877563929"
     },
     "user_tz": -120
    },
    "id": "77KRHlFFhhNG",
    "outputId": "dba6b184-6bec-447d-abef-369969bbf0ad"
   },
   "outputs": [],
   "source": [
    "# To download the weights from Google Colab\n",
    "#!rm -r ./sample_data\n",
    "#!zip -r /content/Asterix_dueling.zip /content\n",
    "#from google.colab import files\n",
    "#files.download('Asterix_dueling.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
